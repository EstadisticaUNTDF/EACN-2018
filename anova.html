<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Estadística Avanzada para Ciencias Naturales</title>
  <meta name="description" content="Un libro con la teoría, ejemplos y práctica de Estadística Avanzada para Ciencias Naturales.">
  <meta name="generator" content="bookdown 0.7.1 and GitBook 2.6.7">

  <meta property="og:title" content="Estadística Avanzada para Ciencias Naturales" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Un libro con la teoría, ejemplos y práctica de Estadística Avanzada para Ciencias Naturales." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Estadística Avanzada para Ciencias Naturales" />
  
  <meta name="twitter:description" content="Un libro con la teoría, ejemplos y práctica de Estadística Avanzada para Ciencias Naturales." />
  

<meta name="author" content="Dr. Luciano Selzer">


<meta name="date" content="2018-03-19">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="manejo-de-datos.html">
<link rel="next" href="problemas-anova-simple.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Laboratorios de Estadística Avanzada</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Reglamento</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#asistencia-a-clases-participacion-y-evaluacion-de-pares"><i class="fa fa-check"></i><b>1.1</b> Asistencia a clases, participación y evaluación de pares</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#entrega-de-ejercicios"><i class="fa fa-check"></i><b>1.2</b> Entrega de Ejercicios</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#laboratorios"><i class="fa fa-check"></i><b>1.3</b> Laboratorios</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#cuestionario-de-comprension"><i class="fa fa-check"></i><b>1.4</b> Cuestionario de Comprensión</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#parciales"><i class="fa fa-check"></i><b>1.5</b> Parciales</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#cronograma"><i class="fa fa-check"></i><b>1.6</b> Cronograma</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduccion-a-r-y-rstudio.html"><a href="introduccion-a-r-y-rstudio.html"><i class="fa fa-check"></i><b>2</b> Introducción a <em>R</em> y RStudio</a><ul>
<li class="chapter" data-level="2.1" data-path="introduccion-a-r-y-rstudio.html"><a href="introduccion-a-r-y-rstudio.html#rstudio"><i class="fa fa-check"></i><b>2.1</b> RStudio</a></li>
<li class="chapter" data-level="2.2" data-path="introduccion-a-r-y-rstudio.html"><a href="introduccion-a-r-y-rstudio.html#analisis-reproducible"><i class="fa fa-check"></i><b>2.2</b> Análisis Reproducible</a><ul>
<li class="chapter" data-level="2.2.1" data-path="introduccion-a-r-y-rstudio.html"><a href="introduccion-a-r-y-rstudio.html#rmarkdown"><i class="fa fa-check"></i><b>2.2.1</b> Rmarkdown</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduccion-a-r-y-rstudio.html"><a href="introduccion-a-r-y-rstudio.html#integrando-codigo"><i class="fa fa-check"></i><b>2.3</b> Integrando código</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="visualizacion-de-datos.html"><a href="visualizacion-de-datos.html"><i class="fa fa-check"></i><b>3</b> Visualización de Datos</a><ul>
<li class="chapter" data-level="3.1" data-path="visualizacion-de-datos.html"><a href="visualizacion-de-datos.html#introduccion"><i class="fa fa-check"></i><b>3.1</b> Introducción</a></li>
<li class="chapter" data-level="3.2" data-path="visualizacion-de-datos.html"><a href="visualizacion-de-datos.html#el-conjunto-de-datos-mpg"><i class="fa fa-check"></i><b>3.2</b> El conjunto de datos <code>mpg</code></a></li>
<li class="chapter" data-level="3.3" data-path="visualizacion-de-datos.html"><a href="visualizacion-de-datos.html#graficos-con-ggplot"><i class="fa fa-check"></i><b>3.3</b> Gráficos con ggplot</a></li>
<li class="chapter" data-level="3.4" data-path="visualizacion-de-datos.html"><a href="visualizacion-de-datos.html#mapeando"><i class="fa fa-check"></i><b>3.4</b> Mapeando</a></li>
<li class="chapter" data-level="3.5" data-path="visualizacion-de-datos.html"><a href="visualizacion-de-datos.html#formas-geometricas"><i class="fa fa-check"></i><b>3.5</b> Formas geometricas</a></li>
<li class="chapter" data-level="3.6" data-path="visualizacion-de-datos.html"><a href="visualizacion-de-datos.html#transformaciones-estadisticas"><i class="fa fa-check"></i><b>3.6</b> Transformaciones Estadísticas</a></li>
<li class="chapter" data-level="3.7" data-path="visualizacion-de-datos.html"><a href="visualizacion-de-datos.html#ajuste-de-posiciones"><i class="fa fa-check"></i><b>3.7</b> Ajuste de Posiciones</a></li>
<li class="chapter" data-level="3.8" data-path="visualizacion-de-datos.html"><a href="visualizacion-de-datos.html#sistemas-de-coordenadas"><i class="fa fa-check"></i><b>3.8</b> Sistemas de Coordenadas</a></li>
<li class="chapter" data-level="3.9" data-path="visualizacion-de-datos.html"><a href="visualizacion-de-datos.html#personalizando-el-grafico"><i class="fa fa-check"></i><b>3.9</b> Personalizando el gráfico</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html"><i class="fa fa-check"></i><b>4</b> Manejo de datos</a><ul>
<li class="chapter" data-level="4.1" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html#seleccionando-datos"><i class="fa fa-check"></i><b>4.1</b> Seleccionando datos</a></li>
<li class="chapter" data-level="4.2" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html#seleccionando-columnas"><i class="fa fa-check"></i><b>4.2</b> Seleccionando columnas</a></li>
<li class="chapter" data-level="4.3" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html#agregando-columnas"><i class="fa fa-check"></i><b>4.3</b> Agregando columnas</a></li>
<li class="chapter" data-level="4.4" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html#operaciones-por-grupos"><i class="fa fa-check"></i><b>4.4</b> Operaciones por grupos</a></li>
<li class="chapter" data-level="4.5" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html#formato-ancho-y-formato-largo"><i class="fa fa-check"></i><b>4.5</b> Formato Ancho y Formato Largo</a></li>
<li class="chapter" data-level="4.6" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html#por-su-cuenta"><i class="fa fa-check"></i><b>4.6</b> Por su cuenta</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>5</b> ANOVA</a><ul>
<li class="chapter" data-level="5.1" data-path="anova.html"><a href="anova.html#algunos-conceptos-importantes"><i class="fa fa-check"></i><b>5.1</b> Algunos conceptos importantes</a></li>
<li class="chapter" data-level="5.2" data-path="anova.html"><a href="anova.html#diseno-de-estudios-de-anova"><i class="fa fa-check"></i><b>5.2</b> Diseño de Estudios de ANOVA</a></li>
<li class="chapter" data-level="5.3" data-path="anova.html"><a href="anova.html#planificacion-de-experimentos"><i class="fa fa-check"></i><b>5.3</b> Planificación De Experimentos</a></li>
<li class="chapter" data-level="5.4" data-path="anova.html"><a href="anova.html#usos-del-anova"><i class="fa fa-check"></i><b>5.4</b> Usos Del ANOVA</a></li>
<li class="chapter" data-level="5.5" data-path="anova.html"><a href="anova.html#modelo-i-de-anova.-niveles-del-factor-fijos"><i class="fa fa-check"></i><b>5.5</b> MODELO I DE ANOVA. NIVELES DEL FACTOR FIJOS</a><ul>
<li class="chapter" data-level="5.5.1" data-path="anova.html"><a href="anova.html#distincion-entre-modelos-i-y-ii-de-anova"><i class="fa fa-check"></i><b>5.5.1</b> Distinción Entre Modelos I Y II de ANOVA</a></li>
<li class="chapter" data-level="5.5.2" data-path="anova.html"><a href="anova.html#ideas-basicas"><i class="fa fa-check"></i><b>5.5.2</b> Ideas Básicas</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="anova.html"><a href="anova.html#comprobacion-de-los-supuestos"><i class="fa fa-check"></i><b>5.6</b> Comprobación de los Supuestos</a><ul>
<li class="chapter" data-level="5.6.1" data-path="anova.html"><a href="anova.html#prueba-para-igualdad-de-varianzas"><i class="fa fa-check"></i><b>5.6.1</b> Prueba para igualdad de varianzas</a></li>
<li class="chapter" data-level="5.6.2" data-path="anova.html"><a href="anova.html#prueba-de-kolmogorov---smirnov-modificacion-de-lilliefors-para-estudiar-normalidad"><i class="fa fa-check"></i><b>5.6.2</b> Prueba de Kolmogorov - Smirnov (modificación de Lilliefors) para estudiar Normalidad</a></li>
<li class="chapter" data-level="5.6.3" data-path="anova.html"><a href="anova.html#residuos"><i class="fa fa-check"></i><b>5.6.3</b> Residuos</a></li>
<li class="chapter" data-level="5.6.4" data-path="anova.html"><a href="anova.html#graficos-de-residuos"><i class="fa fa-check"></i><b>5.6.4</b> Gráficos de Residuos</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="anova.html"><a href="anova.html#transformaciones"><i class="fa fa-check"></i><b>5.7</b> Transformaciones</a><ul>
<li class="chapter" data-level="5.7.1" data-path="anova.html"><a href="anova.html#transformaciones-para-estabilizar-las-varianzas"><i class="fa fa-check"></i><b>5.7.1</b> Transformaciones para estabilizar las Varianzas</a></li>
<li class="chapter" data-level="5.7.2" data-path="anova.html"><a href="anova.html#transformaciones-para-corregir-la-falta-de-normalidad"><i class="fa fa-check"></i><b>5.7.2</b> Transformaciones para corregir la falta de normalidad</a></li>
<li class="chapter" data-level="5.7.3" data-path="anova.html"><a href="anova.html#efectos-del-alejamiento-de-los-supuestos-del-modelo"><i class="fa fa-check"></i><b>5.7.3</b> Efectos Del Alejamiento De Los Supuestos Del Modelo</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="anova.html"><a href="anova.html#formulacion-del-modelo-i-de-anova."><i class="fa fa-check"></i><b>5.8</b> Formulación Del Modelo I De ANOVA.</a><ul>
<li class="chapter" data-level="5.8.1" data-path="anova.html"><a href="anova.html#caracteristicas-importantes-del-modelo"><i class="fa fa-check"></i><b>5.8.1</b> Características importantes del modelo</a></li>
<li class="chapter" data-level="5.8.2" data-path="anova.html"><a href="anova.html#interpretacion-de-las-medias-de-los-niveles-del-factor"><i class="fa fa-check"></i><b>5.8.2</b> Interpretación De Las Medias De Los Niveles Del Factor</a></li>
<li class="chapter" data-level="5.8.3" data-path="anova.html"><a href="anova.html#ajustando-el-modelo"><i class="fa fa-check"></i><b>5.8.3</b> Ajustando El Modelo</a></li>
<li class="chapter" data-level="5.8.4" data-path="anova.html"><a href="anova.html#estimadores-de-minimos-cuadrados"><i class="fa fa-check"></i><b>5.8.4</b> Estimadores De Mínimos Cuadrados</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="anova.html"><a href="anova.html#particion-de-la-suma-de-cuadrados-total"><i class="fa fa-check"></i><b>5.9</b> Partición De La Suma De Cuadrados Total</a><ul>
<li class="chapter" data-level="5.9.1" data-path="anova.html"><a href="anova.html#formulas-computatorias"><i class="fa fa-check"></i><b>5.9.1</b> Fórmulas computatorias</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="anova.html"><a href="anova.html#grados-de-libertad"><i class="fa fa-check"></i><b>5.10</b> Grados De Libertad</a></li>
<li class="chapter" data-level="5.11" data-path="anova.html"><a href="anova.html#cuadrados-medios"><i class="fa fa-check"></i><b>5.11</b> Cuadrados Medios</a><ul>
<li class="chapter" data-level="5.11.1" data-path="anova.html"><a href="anova.html#esperanza-de-los-cuadrados-medios"><i class="fa fa-check"></i><b>5.11.1</b> Esperanza de los Cuadrados Medios</a></li>
<li class="chapter" data-level="5.11.2" data-path="anova.html"><a href="anova.html#comentarios-1"><i class="fa fa-check"></i><b>5.11.2</b> Comentarios</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="anova.html"><a href="anova.html#prueba-f-para-la-igualdad-de-las-medias-de-los-niveles-del-factor"><i class="fa fa-check"></i><b>5.12</b> Prueba F para la Igualdad de las Medias de los Niveles del Factor</a><ul>
<li class="chapter" data-level="5.12.1" data-path="anova.html"><a href="anova.html#prueba-estadistica"><i class="fa fa-check"></i><b>5.12.1</b> Prueba Estadística</a></li>
<li class="chapter" data-level="5.12.2" data-path="anova.html"><a href="anova.html#distribucion-de-mathbffmathbf"><i class="fa fa-check"></i><b>5.12.2</b> Distribución de <span class="math inline">\(\mathbf{F}^{\mathbf{*}}\)</span></a></li>
<li class="chapter" data-level="5.12.3" data-path="anova.html"><a href="anova.html#regla-de-decision"><i class="fa fa-check"></i><b>5.12.3</b> Regla De Decisión</a></li>
<li class="chapter" data-level="5.12.4" data-path="anova.html"><a href="anova.html#comentario"><i class="fa fa-check"></i><b>5.12.4</b> Comentario</a></li>
</ul></li>
<li class="chapter" data-level="5.13" data-path="anova.html"><a href="anova.html#formulacion-alternativa-del-modelo-i"><i class="fa fa-check"></i><b>5.13</b> Formulación Alternativa Del Modelo I</a><ul>
<li class="chapter" data-level="5.13.1" data-path="anova.html"><a href="anova.html#definicion-de-mathbfmu_mathbfbullet"><i class="fa fa-check"></i><b>5.13.1</b> Definición de <span class="math inline">\(\mathbf{\mu}_{\mathbf{\bullet}}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="5.14" data-path="anova.html"><a href="anova.html#prueba-para-la-igualdad-de-las-medias-de-los-niveles-del-factor"><i class="fa fa-check"></i><b>5.14</b> Prueba Para La Igualdad De Las Medias De Los Niveles Del Factor</a></li>
<li class="chapter" data-level="5.15" data-path="anova.html"><a href="anova.html#analisis-de-los-efectos-del-nivel-del-factor"><i class="fa fa-check"></i><b>5.15</b> Análisis De Los Efectos Del Nivel Del Factor</a><ul>
<li class="chapter" data-level="5.15.1" data-path="anova.html"><a href="anova.html#graficos-de-las-estimaciones-de-las-medias-de-los-niveles-del-factor"><i class="fa fa-check"></i><b>5.15.1</b> Gráficos de las estimaciones de las medias de los niveles del factor</a></li>
<li class="chapter" data-level="5.15.2" data-path="anova.html"><a href="anova.html#estimacion-de-los-efectos-de-los-niveles-del-factor"><i class="fa fa-check"></i><b>5.15.2</b> Estimación de los efectos de los niveles del factor</a></li>
<li class="chapter" data-level="5.15.3" data-path="anova.html"><a href="anova.html#comparaciones-multiples"><i class="fa fa-check"></i><b>5.15.3</b> Comparaciones múltiples</a></li>
</ul></li>
<li class="chapter" data-level="5.16" data-path="anova.html"><a href="anova.html#planificacion-del-tamano-muestral"><i class="fa fa-check"></i><b>5.16</b> Planificación Del Tamaño Muestral</a><ul>
<li class="chapter" data-level="5.16.1" data-path="anova.html"><a href="anova.html#potencia-de-la-prueba-f"><i class="fa fa-check"></i><b>5.16.1</b> Potencia De La Prueba F</a></li>
</ul></li>
<li class="chapter" data-level="5.17" data-path="anova.html"><a href="anova.html#modelo-ii-de-anova-niveles-del-factor-aleatorios"><i class="fa fa-check"></i><b>5.17</b> Modelo II De ANOVA: Niveles Del Factor Aleatorios</a><ul>
<li class="chapter" data-level="5.17.1" data-path="anova.html"><a href="anova.html#modelo-aleatorio-de-medias-de-celdas."><i class="fa fa-check"></i><b>5.17.1</b> Modelo Aleatorio de Medias de Celdas.</a></li>
<li class="chapter" data-level="5.17.2" data-path="anova.html"><a href="anova.html#caracteristicas-importantes-del-modelo-1"><i class="fa fa-check"></i><b>5.17.2</b> Características importantes del Modelo</a></li>
<li class="chapter" data-level="5.17.3" data-path="anova.html"><a href="anova.html#cuestiones-de-interes"><i class="fa fa-check"></i><b>5.17.3</b> Cuestiones de Interés</a></li>
<li class="chapter" data-level="5.17.4" data-path="anova.html"><a href="anova.html#prueba-para-mathbfsigma_mathbfmumathbf2-0"><i class="fa fa-check"></i><b>5.17.4</b> Prueba para <span class="math inline">\(\mathbf{\sigma}_{\mathbf{\mu}}^{\mathbf{2}}\)</span> = 0</a></li>
<li class="chapter" data-level="5.17.5" data-path="anova.html"><a href="anova.html#estimacion-de-mathbfmu_mathbfbullet"><i class="fa fa-check"></i><b>5.17.5</b> Estimación De <span class="math inline">\(\mathbf{\mu}_{\mathbf{\bullet}}\)</span></a></li>
<li class="chapter" data-level="5.17.6" data-path="anova.html"><a href="anova.html#estimacion-de-sigma_mu2left-sigma_mu2sigma2-right"><i class="fa fa-check"></i><b>5.17.6</b> Estimación De <span class="math inline">\(\sigma_{\mu}^2/\left ( \sigma_{\mu}^2+\sigma^2 \right )\)</span></a></li>
<li class="chapter" data-level="5.17.7" data-path="anova.html"><a href="anova.html#modelo-de-efectos-aleatorios"><i class="fa fa-check"></i><b>5.17.7</b> Modelo De Efectos Aleatorios</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="problemas-anova-simple.html"><a href="problemas-anova-simple.html"><i class="fa fa-check"></i><b>6</b> Problemas ANOVA Simple</a><ul>
<li class="chapter" data-level="6.0.1" data-path="problemas-anova-simple.html"><a href="problemas-anova-simple.html#recordatorio"><i class="fa fa-check"></i><b>6.0.1</b> Recordatorio</a></li>
<li class="chapter" data-level="6.1" data-path="problemas-anova-simple.html"><a href="problemas-anova-simple.html#problemas"><i class="fa fa-check"></i><b>6.1</b> Problemas</a><ul>
<li class="chapter" data-level="6.1.1" data-path="problemas-anova-simple.html"><a href="problemas-anova-simple.html#contrastes"><i class="fa fa-check"></i><b>6.1.1</b> Contrastes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html"><i class="fa fa-check"></i><b>7</b> ANOVA DE DOS FACTORES</a><ul>
<li class="chapter" data-level="7.1" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#ventajas-de-los-estudios-multifactoriales"><i class="fa fa-check"></i><b>7.1</b> Ventajas de los estudios multifactoriales</a><ul>
<li class="chapter" data-level="7.1.1" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#eficiencia"><i class="fa fa-check"></i><b>7.1.1</b> Eficiencia:</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#elementos-del-modelo"><i class="fa fa-check"></i><b>7.2</b> Elementos del Modelo</a><ul>
<li class="chapter" data-level="7.2.1" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#efectos-principales"><i class="fa fa-check"></i><b>7.2.1</b> Efectos principales</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#representacion-grafica"><i class="fa fa-check"></i><b>7.3</b> Representación gráfica</a></li>
<li class="chapter" data-level="7.4" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#interaccion"><i class="fa fa-check"></i><b>7.4</b> Interacción</a><ul>
<li class="chapter" data-level="7.4.1" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#interacciones-no-importantes"><i class="fa fa-check"></i><b>7.4.1</b> Interacciones no importantes</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#modelo-i-para-estudios-de-dos-factores"><i class="fa fa-check"></i><b>7.5</b> MODELO I PARA ESTUDIOS DE DOS FACTORES</a><ul>
<li class="chapter" data-level="7.5.1" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#modelo-de-las-medias-de-celdas"><i class="fa fa-check"></i><b>7.5.1</b> Modelo de las medias de celdas</a></li>
<li class="chapter" data-level="7.5.2" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#modelo-de-los-efectos-de-los-factores"><i class="fa fa-check"></i><b>7.5.2</b> Modelo de los efectos de los factores</a></li>
<li class="chapter" data-level="7.5.3" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#anova-modelo-i"><i class="fa fa-check"></i><b>7.5.3</b> ANOVA (MODELO I)</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#prueba-de-f"><i class="fa fa-check"></i><b>7.6</b> Prueba de F</a></li>
<li class="chapter" data-level="7.7" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#contrastes-1"><i class="fa fa-check"></i><b>7.7</b> Contrastes</a><ul>
<li class="chapter" data-level="7.7.1" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#entre-filas"><i class="fa fa-check"></i><b>7.7.1</b> Entre Filas</a></li>
<li class="chapter" data-level="7.7.2" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#entre-columnas"><i class="fa fa-check"></i><b>7.7.2</b> Entre columnas</a></li>
<li class="chapter" data-level="7.7.3" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#interaccion-1"><i class="fa fa-check"></i><b>7.7.3</b> Interacción</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#potencia-de-la-prueba-f-1"><i class="fa fa-check"></i><b>7.8</b> Potencia de la prueba F</a><ul>
<li class="chapter" data-level="7.8.1" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#interaccion-2"><i class="fa fa-check"></i><b>7.8.1</b> Interacción</a></li>
<li class="chapter" data-level="7.8.2" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#prueba-para-el-factor-principal-a"><i class="fa fa-check"></i><b>7.8.2</b> Prueba para el factor principal A:</a></li>
<li class="chapter" data-level="7.8.3" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#prueba-para-el-factor-principal-b"><i class="fa fa-check"></i><b>7.8.3</b> Prueba para el factor principal B:</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#caso-de-una-observacion-por-tratamiento"><i class="fa fa-check"></i><b>7.9</b> CASO DE UNA OBSERVACIÓN POR TRATAMIENTO</a><ul>
<li class="chapter" data-level="7.9.1" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#modelo-sin-interaccion"><i class="fa fa-check"></i><b>7.9.1</b> Modelo sin interacción</a></li>
<li class="chapter" data-level="7.9.2" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#prueba-de-tukey-aditividad"><i class="fa fa-check"></i><b>7.9.2</b> Prueba de Tukey (Aditividad)</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#modelo-ii-y-modelo-iii-para-estudios-de-dos-factores"><i class="fa fa-check"></i><b>7.10</b> MODELO II Y MODELO III PARA ESTUDIOS DE DOS FACTORES</a><ul>
<li class="chapter" data-level="7.10.1" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#modelo-aleatorio-modelo-ii"><i class="fa fa-check"></i><b>7.10.1</b> Modelo aleatorio (Modelo II)</a></li>
<li class="chapter" data-level="7.10.2" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#modelo-mixto-modelo-iii"><i class="fa fa-check"></i><b>7.10.2</b> Modelo Mixto (Modelo III)</a></li>
<li class="chapter" data-level="7.10.3" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#pruebas-estadisticas"><i class="fa fa-check"></i><b>7.10.3</b> Pruebas estadísticas</a></li>
<li class="chapter" data-level="7.10.4" data-path="anova-de-dos-factores.html"><a href="anova-de-dos-factores.html#estimacion-de-los-componentes-de-la-varianza"><i class="fa fa-check"></i><b>7.10.4</b> Estimación de los componentes de la varianza</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="problemas-anova-dos-factores.html"><a href="problemas-anova-dos-factores.html"><i class="fa fa-check"></i><b>8</b> Problemas ANOVA Dos Factores</a><ul>
<li class="chapter" data-level="8.1" data-path="problemas-anova-dos-factores.html"><a href="problemas-anova-dos-factores.html#formulas-con-mas-de-una-variable-independiente"><i class="fa fa-check"></i><b>8.1</b> Formulas con más de una variable independiente</a><ul>
<li class="chapter" data-level="8.1.1" data-path="problemas-anova-dos-factores.html"><a href="problemas-anova-dos-factores.html#test-de-aditividad-de-tukey."><i class="fa fa-check"></i><b>8.1.1</b> Test de aditividad de Tukey.</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="problemas-anova-dos-factores.html"><a href="problemas-anova-dos-factores.html#problemas-1"><i class="fa fa-check"></i><b>8.2</b> Problemas</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><i class="fa fa-check"></i><b>9</b> Prueba de Wilcoxon-Mann-Whitney para dos pruebas independientes</a><ul>
<li class="chapter" data-level="9.1" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#datos"><i class="fa fa-check"></i><b>9.1</b> Datos</a></li>
<li class="chapter" data-level="9.2" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#supuestos"><i class="fa fa-check"></i><b>9.2</b> Supuestos</a></li>
<li class="chapter" data-level="9.3" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#np-algoritmo"><i class="fa fa-check"></i><b>9.3</b> Procedimiento básico</a><ul>
<li class="chapter" data-level="9.3.1" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#ejemplo"><i class="fa fa-check"></i><b>9.3.1</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#estadisticos"><i class="fa fa-check"></i><b>9.4</b> Estadísticos</a><ul>
<li class="chapter" data-level="9.4.1" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#variante-wilcoxon-w"><i class="fa fa-check"></i><b>9.4.1</b> Variante Wilcoxon (W)</a></li>
<li class="chapter" data-level="9.4.2" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#variante-mann-whitney-u"><i class="fa fa-check"></i><b>9.4.2</b> Variante Mann-Whitney (U)</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#hipotesis"><i class="fa fa-check"></i><b>9.5</b> Hipótesis</a><ul>
<li class="chapter" data-level="9.5.1" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#prueba-a-dos-colas"><i class="fa fa-check"></i><b>9.5.1</b> Prueba a dos colas</a></li>
<li class="chapter" data-level="9.5.2" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#prueba-de-una-cola-a-la-izquierda"><i class="fa fa-check"></i><b>9.5.2</b> Prueba de una cola a la izquierda</a></li>
<li class="chapter" data-level="9.5.3" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#prueba-de-una-cola-a-la-derecha"><i class="fa fa-check"></i><b>9.5.3</b> Prueba de una cola a la derecha</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#ejemplo-2"><i class="fa fa-check"></i><b>9.6</b> Ejemplo 2</a></li>
<li class="chapter" data-level="9.7" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#prueba-de-wilcoxon-de-rangos-con-signo-para-muestras-apareadas"><i class="fa fa-check"></i><b>9.7</b> Prueba de Wilcoxon de rangos con signo para muestras apareadas</a><ul>
<li class="chapter" data-level="9.7.1" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#supuestos-1"><i class="fa fa-check"></i><b>9.7.1</b> Supuestos</a></li>
<li class="chapter" data-level="9.7.2" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#estadisticos-1"><i class="fa fa-check"></i><b>9.7.2</b> Estadísticos</a></li>
<li class="chapter" data-level="9.7.3" data-path="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html"><a href="prueba-de-wilcoxon-mann-whitney-para-dos-pruebas-independientes.html#hipotesis-1"><i class="fa fa-check"></i><b>9.7.3</b> Hipótesis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ejercicios-de-dos-muestras-no-parametrico.html"><a href="ejercicios-de-dos-muestras-no-parametrico.html"><i class="fa fa-check"></i><b>10</b> Ejercicios de dos muestras no paramétrico</a><ul>
<li class="chapter" data-level="10.1" data-path="ejercicios-de-dos-muestras-no-parametrico.html"><a href="ejercicios-de-dos-muestras-no-parametrico.html#reproduciendo-el-algoritmo-manualmente"><i class="fa fa-check"></i><b>10.1</b> Reproduciendo el algoritmo manualmente</a></li>
<li class="chapter" data-level="10.2" data-path="ejercicios-de-dos-muestras-no-parametrico.html"><a href="ejercicios-de-dos-muestras-no-parametrico.html#funciones-no-parametricas-en-r"><i class="fa fa-check"></i><b>10.2</b> Funciones no paramétricas en <em>R</em></a></li>
<li class="chapter" data-level="10.3" data-path="ejercicios-de-dos-muestras-no-parametrico.html"><a href="ejercicios-de-dos-muestras-no-parametrico.html#formulas"><i class="fa fa-check"></i><b>10.3</b> Fórmulas</a></li>
<li class="chapter" data-level="10.4" data-path="ejercicios-de-dos-muestras-no-parametrico.html"><a href="ejercicios-de-dos-muestras-no-parametrico.html#muestras-apareadas"><i class="fa fa-check"></i><b>10.4</b> Muestras apareadas</a></li>
<li class="chapter" data-level="10.5" data-path="ejercicios-de-dos-muestras-no-parametrico.html"><a href="ejercicios-de-dos-muestras-no-parametrico.html#problemas-2"><i class="fa fa-check"></i><b>10.5</b> Problemas</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="anova-no-parametrico.html"><a href="anova-no-parametrico.html"><i class="fa fa-check"></i><b>11</b> ANOVA No Paramétrico</a><ul>
<li class="chapter" data-level="11.1" data-path="anova-no-parametrico.html"><a href="anova-no-parametrico.html#pruebas-para-varias-muestras-independientes"><i class="fa fa-check"></i><b>11.1</b> Pruebas para varias muestras independientes</a><ul>
<li class="chapter" data-level="11.1.1" data-path="anova-no-parametrico.html"><a href="anova-no-parametrico.html#prueba-de-la-mediana"><i class="fa fa-check"></i><b>11.1.1</b> Prueba de la mediana</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="anova-no-parametrico.html"><a href="anova-no-parametrico.html#prueba-de-kruskal-wallis"><i class="fa fa-check"></i><b>11.2</b> Prueba de Kruskal-Wallis</a><ul>
<li class="chapter" data-level="11.2.1" data-path="anova-no-parametrico.html"><a href="anova-no-parametrico.html#datos-2"><i class="fa fa-check"></i><b>11.2.1</b> Datos</a></li>
<li class="chapter" data-level="11.2.2" data-path="anova-no-parametrico.html"><a href="anova-no-parametrico.html#supuestos-3"><i class="fa fa-check"></i><b>11.2.2</b> Supuestos</a></li>
<li class="chapter" data-level="11.2.3" data-path="anova-no-parametrico.html"><a href="anova-no-parametrico.html#procedimiento-1"><i class="fa fa-check"></i><b>11.2.3</b> Procedimiento</a></li>
<li class="chapter" data-level="11.2.4" data-path="anova-no-parametrico.html"><a href="anova-no-parametrico.html#hipotesis-3"><i class="fa fa-check"></i><b>11.2.4</b> Hipótesis</a></li>
<li class="chapter" data-level="11.2.5" data-path="anova-no-parametrico.html"><a href="anova-no-parametrico.html#contrastes-3"><i class="fa fa-check"></i><b>11.2.5</b> Contrastes</a></li>
<li class="chapter" data-level="11.2.6" data-path="anova-no-parametrico.html"><a href="anova-no-parametrico.html#comentarios-3"><i class="fa fa-check"></i><b>11.2.6</b> Comentarios</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="disenos-experimentales.html"><a href="disenos-experimentales.html"><i class="fa fa-check"></i><b>12</b> DISEÑOS EXPERIMENTALES</a><ul>
<li class="chapter" data-level="12.1" data-path="disenos-experimentales.html"><a href="disenos-experimentales.html#bloques-al-azar"><i class="fa fa-check"></i><b>12.1</b> Bloques al azar</a><ul>
<li class="chapter" data-level="12.1.1" data-path="disenos-experimentales.html"><a href="disenos-experimentales.html#diseno-de-experimentos"><i class="fa fa-check"></i><b>12.1.1</b> Diseño de experimentos</a></li>
<li class="chapter" data-level="12.1.2" data-path="disenos-experimentales.html"><a href="disenos-experimentales.html#elementos-de-los-disenos-de-bloques-al-azar"><i class="fa fa-check"></i><b>12.1.2</b> Elementos de los Diseños de Bloques al Azar</a></li>
<li class="chapter" data-level="12.1.3" data-path="disenos-experimentales.html"><a href="disenos-experimentales.html#criterios-para-definir-los-bloques"><i class="fa fa-check"></i><b>12.1.3</b> Criterios para definir los bloques</a></li>
<li class="chapter" data-level="12.1.4" data-path="disenos-experimentales.html"><a href="disenos-experimentales.html#ventajas-y-desventajas"><i class="fa fa-check"></i><b>12.1.4</b> Ventajas y desventajas</a></li>
<li class="chapter" data-level="12.1.5" data-path="disenos-experimentales.html"><a href="disenos-experimentales.html#modelo"><i class="fa fa-check"></i><b>12.1.5</b> Modelo</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="disenos-experimentales.html"><a href="disenos-experimentales.html#analisis-de-la-varianza-y-pruebas"><i class="fa fa-check"></i><b>12.2</b> Análisis de la varianza y pruebas</a><ul>
<li class="chapter" data-level="12.2.1" data-path="disenos-experimentales.html"><a href="disenos-experimentales.html#analisis-de-la-varianza"><i class="fa fa-check"></i><b>12.2.1</b> Análisis de la varianza</a></li>
<li class="chapter" data-level="12.2.2" data-path="disenos-experimentales.html"><a href="disenos-experimentales.html#prueba-de-tukey-de-aditividad"><i class="fa fa-check"></i><b>12.2.2</b> Prueba de Tukey de Aditividad</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="regresion.html"><a href="regresion.html"><i class="fa fa-check"></i><b>13</b> Regresión</a><ul>
<li class="chapter" data-level="13.1" data-path="regresion.html"><a href="regresion.html#regresion-lineal-simple"><i class="fa fa-check"></i><b>13.1</b> Regresión Lineal Simple</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ordenacion-en-espacios-reducidos.html"><a href="ordenacion-en-espacios-reducidos.html"><i class="fa fa-check"></i><b>14</b> Ordenación en Espacios Reducidos</a><ul>
<li class="chapter" data-level="14.1" data-path="ordenacion-en-espacios-reducidos.html"><a href="ordenacion-en-espacios-reducidos.html#analisis-de-componentes-principales"><i class="fa fa-check"></i><b>14.1</b> Análisis de componentes principales</a><ul>
<li class="chapter" data-level="14.1.1" data-path="ordenacion-en-espacios-reducidos.html"><a href="ordenacion-en-espacios-reducidos.html#biplots"><i class="fa fa-check"></i><b>14.1.1</b> Biplots</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="ordenacion-en-espacios-reducidos.html"><a href="ordenacion-en-espacios-reducidos.html#componentes-principales-de-una-matriz-de-correlacion"><i class="fa fa-check"></i><b>14.2</b> Componentes principales de una matriz de correlación</a></li>
<li class="chapter" data-level="14.3" data-path="ordenacion-en-espacios-reducidos.html"><a href="ordenacion-en-espacios-reducidos.html#cuantos-componentes-son-significativos"><i class="fa fa-check"></i><b>14.3</b> ¿Cuantos componentes son significativos?</a></li>
<li class="chapter" data-level="14.4" data-path="ordenacion-en-espacios-reducidos.html"><a href="ordenacion-en-espacios-reducidos.html#mal-uso-de-los-componentes-principales"><i class="fa fa-check"></i><b>14.4</b> Mal uso de los componentes principales</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística Avanzada para Ciencias Naturales</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="anova" class="section level1">
<h1><span class="header-section-number">Capítulo 5</span> ANOVA</h1>
<div id="algunos-conceptos-importantes" class="section level2">
<h2><span class="header-section-number">5.1</span> Algunos conceptos importantes</h2>
<p><strong>Factor</strong>: Un factor es una variable independiente a ser estudiada en una
investigación. Ejemplo: Temperatura, Dieta</p>
<p><strong>Nivel</strong>: El nivel de un factor es una forma particular de ese factor. Ejemplo:
Temperatura: 0ºC, 10ºC y 20ºC. Dieta: Con aditivos proteicos y Sin aditivos
proteicos</p>
<p><strong>Estudios Uní y Multifactoriales:</strong> Estudios de un factor, únicamente un factor
es de interés. En estudios Multifactoriales, dos o más factores son investigados
simultáneamente. Ejemplo: Un factor: cantidades de suplemento de proteínas de
una clase determinada. Más de un factor: cantidades y clases de suplementos de
proteínas.</p>
<p><strong>Factores Experimentales y de Clasificación:</strong> En cualquier investigación
basada sobre datos observacionales, los factores bajo estudio son factores de
clasificación. Un factor de clasificación corresponde a la característica de las
unidades bajo estudio y no las que están bajo control del investigador, no
pueden ser manipuladas experimentalmente. Por otro lado, un factor experimental
es aquel donde los niveles del factor son asignados al azar a las unidades
experimentales.</p>
<p><strong>Factores cualitativos y cuantitativos:</strong> Un factor cualitativo es aquel donde
los niveles difieren con respecto a un atributo cualitativo. Por otro lado, un
factor cuantitativo es aquel que es descrito por una cantidad numérica sobre una
escala.</p>
<p><strong>Tratamientos:</strong> Es el procedimiento cuyo efecto se mide y se compara con otros
tratamientos. En estudios unifactoriales un tratamiento corresponde a un nivel
de un factor. En estudios Multifactoriales, un tratamiento corresponde a una
combinación de niveles de factores.</p>
</div>
<div id="diseno-de-estudios-de-anova" class="section level2">
<h2><span class="header-section-number">5.2</span> Diseño de Estudios de ANOVA</h2>
<p><strong>Elección del tratamiento:</strong> La elección de los tratamientos a ser incluidos en
una investigación es básicamente una decisión del investigador. En una
investigación científica, los tratamientos incluidos deberían poder suministrar
conocimientos sobre el mecanismo subyacente al fenómeno bajo estudio.</p>
<p><strong>Definición del tratamiento:</strong> Al seleccionar un conjunto de tratamientos, es
importante definir cada tratamiento cuidadosamente y considerarlo con respecto a
cada uno de los demás tratamientos para asegurarse, en lo posible, que el
conjunto dé respuestas eficientes relacionadas con los objetivos del
experimento.</p>
<p><strong>Tratamiento Control o Testigo:</strong> Un tratamiento control consiste en la
aplicación de procedimientos idénticos a las unidades experimentales que
aquellos usados con los otros tratamientos, excepto por los efectos bajo
investigación.</p>
<p>Un tratamiento control es requerido cuando la efectividad general de los
tratamientos bajo estudio no es conocida, o cuando la efectividad general de los
tratamientos es conocida pero no es consistente bajo todas las condiciones.</p>
<p><strong>Unidad experimental o unidad básica de estudio:</strong> Es la unidad de material a
la cual se aplica un tratamiento. Es la mínima unidad de muestreo. No siempre
coincide con la unidad de muestreo. Ejemplo: se aplica un tratamiento en una
maceta y se muestrean tres hojas de cada maceta.</p>
<p><strong>Observación individual:</strong> Son las mediciones que se hacen en cada una de las
unidades experimentales.</p>
<p><strong>Muestra:</strong> Es el conjunto de observaciones individuales, se expresa en
términos de observaciones individuales y no de unidades experimentales, es la
única información que uno posee.</p>
</div>
<div id="planificacion-de-experimentos" class="section level2">
<h2><span class="header-section-number">5.3</span> Planificación De Experimentos</h2>
<p>Las inferencias que pueden hacerse, a partir de los resultados de un
experimento, dependen de la forma en que fue hecho el experimento. Es una buena
práctica hacer un proyecto de los propósitos de cualquier experimento. Este
proyecto constará de tres partes:</p>
<p><strong>Enumeración de las finalidades:</strong> debe incluir una determinación del campo
sobre el cual se harán las generalizaciones, o, en otras palabras, la población
respecto de la cual se espera hacer inferencias.</p>
<p><strong>descripción del experimento:</strong> Se ha usado el término tratamiento para
denominar los diferentes procesos cuyos efectos van a ser medidos y comparados.
En la selección de los tratamientos es importante definir claramente cada uno de
ellos y entender el papel que jugará para alcanzar los objetivos del
experimento.</p>
<p><strong>bosquejo del método de análisis de los resultados:</strong> Las características del
experimento que deben ser tenidas en cuenta en la enumeración de finalidades
son: el número de repeticiones, los tipos de material experimental que se van a
usar, las mediciones que se van a hacer. Finalmente, el bosquejo debería
describir, con algún detalle, el método propuesto para sacar conclusiones de los
resultados.</p>
</div>
<div id="usos-del-anova" class="section level2">
<h2><span class="header-section-number">5.4</span> Usos Del ANOVA</h2>
<p>Los estudios de un solo factor son utilizados para comparar efectos de
diferentes niveles de un factor, para determinar el “mejor” nivel del factor y
la semejanza. En estudios multifactoriales, el ANOVA es empleado para determinar
si los diferentes factores interactúan, que factores son claves; cuales
combinaciones de factores son las “mejores”, etc.</p>
</div>
<div id="modelo-i-de-anova.-niveles-del-factor-fijos" class="section level2">
<h2><span class="header-section-number">5.5</span> MODELO I DE ANOVA. NIVELES DEL FACTOR FIJOS</h2>
<div id="distincion-entre-modelos-i-y-ii-de-anova" class="section level3">
<h3><span class="header-section-number">5.5.1</span> Distinción Entre Modelos I Y II de ANOVA</h3>
<p>El modelo I de ANOVA se aplica en casos tales como una comparación de un número
determinado de tratamientos, y donde las conclusiones se restringen a aquellos
niveles del factor incluidos en el estudio. También se conoce como modelo de
efectos fijos. El modelo II de ANOVA se aplica a un tipo diferente de situación,
donde las conclusiones se extenderán a una población de niveles del factor del
cual los niveles bajo estudio son una muestra. Es decir que se trata de un
modelo de efectos aleatorios.</p>
</div>
<div id="ideas-basicas" class="section level3">
<h3><span class="header-section-number">5.5.2</span> Ideas Básicas</h3>
<p>Los elementos básicos del modelo I de ANOVA para un estudio de un factor son muy
simples. Correspondiendo a cada nivel del factor, hay una distribución de
probabilidades de respuestas. El modelo I de ANOVA supone:</p>
<ol style="list-style-type: decimal">
<li><p>Cada una de las distribuciones en probabilidades es <strong>normal</strong></p></li>
<li><p>Cada distribución en probabilidad tiene la <strong>misma varianza</strong> (desviación
estándar).</p></li>
<li><p>Las observaciones para cada nivel del factor son observaciones
<strong>aleatorias</strong> de la correspondiente distribución y son <strong>independientes</strong>
de las observaciones de cualquier otro nivel del factor.</p></li>
</ol>
<div class="figure"><span id="fig:distr-normales"></span>
<img src="anova_files/figure-html/distr-normales-1.png" alt="Densidad de distribuciones de cuatro distribuciones normales con igual varianza y distinta media" width="672" />
<p class="caption">
Figura 5.1: Densidad de distribuciones de cuatro distribuciones normales con igual varianza y distinta media
</p>
</div>
<p>La Figura <a href="anova.html#fig:distr-normales">5.1</a> ilustra estas condiciones: la normalidad de la distribución en
probabilidades y la variabilidad constante. Las distribuciones en probabilidad
difieren sólo con respecto a sus medias. El análisis de los datos de las
muestras de las distribuciones en probabilidades de los niveles de los factores
se desarrolla usualmente en dos pasos:</p>
<p>Determinar si las medias de los niveles de los factores son las mismas.</p>
<p>Si las medias de los niveles del factor no son las mismas, examinar como
difieren y cuales son las consecuencias de las diferencias.</p>
</div>
</div>
<div id="comprobacion-de-los-supuestos" class="section level2">
<h2><span class="header-section-number">5.6</span> Comprobación de los Supuestos</h2>
<p>Los modelos de ANOVA son razonablemente robustos, aunque se produzcan ciertos
alejamientos del supuesto de normalidad.</p>
<div id="prueba-para-igualdad-de-varianzas" class="section level3">
<h3><span class="header-section-number">5.6.1</span> Prueba para igualdad de varianzas</h3>
<div id="prueba-de-bartlett" class="section level4">
<h4><span class="header-section-number">5.6.1.1</span> Prueba de Bartlett</h4>
<p>Las hipótesis son</p>
<p><span class="math display">\[
\begin{aligned}
 H_{0} &amp;: \sigma_{1}^{2} = \sigma_{2}^{2} = \ldots = \sigma_{i}^{2} = \ldots = \sigma_{I}^{2} \\
 H_{a} &amp;: \text{no todos}\ \text{los}\ \sigma_{i}^{2}\ \text{son}\ \text{iguales}
\end{aligned}
\]</span></p>
<p>Sean <span class="math inline">\(S_{1}^{2},\ldots,S_{I}^{2}\)</span>indican las varianzas muestrales de <span class="math inline">\(I\)</span>
poblaciones normales, y <span class="math inline">\(Gl_{i}\)</span> indica los grados de libertad asociados con
la varianza muestral <span class="math inline">\(S_{i}^{2}\)</span>.</p>
<p>Bartlett ha demostrado que una función de <span class="math inline">\(\left\lbrack \ln\left( C\text{MD} \right) - ln(MGD) \right\rbrack\)</span>, (<span class="math inline">\(M\text{GD}\)</span>: media geométrica pesada;
<span class="math inline">\(C\text{MD}\)</span>: cuadrado medio dentro) para grandes tamaños muestrales, sigue
aproximadamente la distribución <span class="math inline">\(\chi^{2}\)</span> con <span class="math inline">\((I-1)\)</span> grados de libertad
cuando las varianzas poblacionales son iguales. La prueba estadística es:</p>
<p><span class="math display">\[
B = \frac{GL_{t}}{C}\left\lbrack \ln\left( CM_D \right) - ln(M\text{MGD}) \right\rbrack
\]</span></p>
<p>, donde</p>
<p><span class="math display">\[
C = 1 + \frac{1}{3\left( I - 1 \right)}\left\lbrack \left( \sum_{i = 1}^{I}\frac{1}{GL_{i}} \right) - \frac{1}{GL_{T}} \right\rbrack
\]</span></p>
<p>El término C es siempre mayor que 1.</p>
<p>La prueba estadística se reduce a:</p>
<p><span class="math display">\[
B = \frac{1}{C}\left\lbrack (GL_{t})\ln\left( CM_D \right) - \sum_{i = 1}^{I}\left( GL_{i} \right)lnS_{i}^{2} \right\rbrack
\]</span></p>
<p>se calcula el estadístico <span class="math inline">\(B\)</span>. La regla de decisión es:</p>
<p>Si <span class="math inline">\(B &lt; \chi_{(1 - \alpha;I - 1)}^{2}\)</span>, no se rechaza <span class="math inline">\(H_{0}\)</span></p>
<p>Si <span class="math inline">\(B &gt; \chi_{(1 - \alpha;I - 1)}^{2}\)</span>, se rechaza <span class="math inline">\(H_{0}\)</span></p>
<p>Esta aproximación se considera apropiada cuando los grados de libertad son
mayores o iguales que cuatro.</p>
<p>Cuando la prueba se usa para un modelo de ANOVA de un factor se tiene:</p>
<p><span class="math inline">\(GL_{i} = n_{i} - 1\)</span> y <span class="math inline">\(GL_{T} = \sum_{i = 1}^{I}\left( n_{i} - 1 \right) = N - I\)</span></p>
<p>La prueba de Bartlett es bastante sensible a la falta de normalidad. Si las
varianzas muestrales son menores que la unidad, sus logaritmos serán negativos.
Por lo tanto, es conveniente utilizar un código multiplicativo para hacer las
varianzas mayores que la unidad. Este código no afecta en modo alguno a la
prueba estadística.</p>
</div>
<div id="prueba-de-levene-modificada" class="section level4">
<h4><span class="header-section-number">5.6.1.2</span> Prueba de Levene Modificada</h4>
<p>Las hipótesis son</p>
<p><span class="math display">\[
\begin{aligned}
H_{0} &amp;:\sigma_{1}^{2} = \sigma_{2}^{2} = \ldots = \sigma_{i}^{2} = \ldots = \sigma_{I}^{2}\\
H_{a} &amp;:\text{no todos}\ \text{los}\ \sigma_{i}^{2}\ \text{son}\ \text{iguales}
\end{aligned}
\]</span></p>
<p>Primero se calcula la desviación absoluta de las <span class="math inline">\(Y_ij\)</span> observaciones de sus
respectivas medianas del nivel del factor <span class="math inline">\(\tilde{Y_{i}}\)</span></p>
<p><span class="math display">\[
d_{ij} = \left| Y_{ij} - \tilde{Y_{i}} \right|
\]</span></p>
<p>Entonces la prueba de Levene determina si los valores esperados de las
desviaciones absolutas son iguales. Si las varianzas son iguales entonces los
valores esperados de las desviaciones absolutas también serán iguales. La prueba
de Levene usa el estadístico <span class="math inline">\(F^{*}\)</span></p>
<p><span class="math display">\[
F_{L}^{*} = \frac{CM_{ET}}{CM_D}
\]</span></p>
<p>donde</p>
<p><span class="math display">\[
CM_{ET} = \frac{\sum n_{i}\left( \overline{d}_{i\bullet}\  - \overline{d}_{\bullet\bullet} \right)^{2}}{I - 1}
\]</span></p>
<p><span class="math display">\[
CM_D = \frac{\sum\sum\left( \overline{d}_{ij}\  - \overline{d}_{i\bullet}\right)^{2}}{N - 1}
\]</span></p>
<p><span class="math display">\[
\overline{d}_{i\bullet} = \sum_{j}^{}\frac{d_{ij}}{n_{i}}
\]</span></p>
<p><span class="math display">\[
\overline{d}_{\cdot \cdot } = \frac{\sum_{}^{}{\sum_{}^{}{d_{ij}}}}{N}
\]</span></p>
<p>Si las varianzas son iguales y los tamaños muestrales no son extremadamente
pequeños, <span class="math inline">\(\mathbf{F}_{\mathbf{L}}^{\mathbf{*}}\)</span> sigue aproximadamente una
distribución <span class="math inline">\(F\)</span> con <span class="math inline">\((I - 1)\)</span> y <span class="math inline">\((N - I)\)</span> grados de libertad.</p>
</div>
</div>
<div id="prueba-de-kolmogorov---smirnov-modificacion-de-lilliefors-para-estudiar-normalidad" class="section level3">
<h3><span class="header-section-number">5.6.2</span> Prueba de Kolmogorov - Smirnov (modificación de Lilliefors) para estudiar Normalidad</h3>
<p>Dada una muestra aleatoria, se calcula su media y su varianza muestral, luego se
calculan los datos normalizados <span class="math inline">\(Z_{i}\)</span>. Se ordenan los datos de menor a
mayor, se calculan las frecuencias acumuladas observadas, las esperadas para los
<span class="math inline">\(Z_{i}\)</span>, y luego se calculan las diferencias, en valor absoluto entre las
frecuencias acumuladas observadas y las esperadas. Se define <span class="math inline">\(D_{max} = max\left| F_{i} - \hat{F_{i}} \right|\)</span> este estadístico se compara con el valor
de tablas <span class="math inline">\(d_{max}\)</span> al nivel de significación <span class="math inline">\(\alpha\)</span>.</p>
</div>
<div id="residuos" class="section level3">
<h3><span class="header-section-number">5.6.3</span> Residuos</h3>
<p>El residuo <span class="math inline">\(\varepsilon_{ij}\)</span> es definido como la diferencia entre el valor observado y el
ajustado:</p>
<p><span class="math display">\[
\varepsilon_{ij} = y_{ij} - \overline{y}_{i\bullet}
\]</span></p>
<p>Así, un residuo representa la desviación de una observación individual de la
respectiva media estimada del nivel del factor. A veces es útil trabajar con los
residuos estandarizados, que se expresan como:</p>
<p><span class="math display">\[
\varepsilon_{\ _{ij}}^{\otimes} = \frac{\varepsilon_{ij} - \overline{\varepsilon}}{\sqrt{CM_D}}
\]</span></p>
<p>Los residuos “<em>semistudentizados</em>”, los residuos “<em>studentizados</em>”, y los
residuos “<em>studentizados borrados</em>” son a menudo útiles para diagnosticar los
alejamientos del modelo de ANOVA.</p>
<p>Los residuos “<em>semistudentizados</em>” se calculan como:</p>
<p><span class="math display">\[
\varepsilon_{\ _{ij}}^{*} = \frac{\varepsilon_{ij}}{\sqrt{CM_D}}
\]</span></p>
<p>Los residuos “<em>studentizados</em>” se calculan como:</p>
<p><span class="math display">\[
r_{ij} = \frac{\varepsilon_{ij}}{S\left( \varepsilon_{ij} \right)}
\]</span></p>
<p>donde</p>
<p><span class="math display">\[
S\left( \varepsilon_{ij} \right) = \sqrt{\frac{CM_D\left( n_{i} - 1 \right)}{n_{i}}}
\]</span></p>
<p>Finalmente, los residuos “<em>studentizados borrados</em>” se calculan</p>
<p><span class="math display">\[
t_{ij} = \varepsilon_{ij}\left\lbrack \frac{N - I - 1}{SC_D\left( 1 - \frac{1}{n_{i}} \right)\varepsilon_{ij}^{2}} \right\rbrack^{\frac{1}{2}}
\]</span></p>
</div>
<div id="graficos-de-residuos" class="section level3">
<h3><span class="header-section-number">5.6.4</span> Gráficos de Residuos</h3>
<p>Estos gráficos son muy importantes para el diagnóstico de problemas con el modelo.
Incluye:</p>
<ol style="list-style-type: decimal">
<li><em>Residuos vs. las medias de tratamientos</em>: Dado que las valores ajustados
de cada nivel de factor se corresponde a la media, todos los valores
de los residuales de ese nivel se alinearán en sobre esa media (Figura
<a href="anova.html#fig:graficos-residuales">5.2</a>-a). Si no hay problemas con el modelo, entonces
los residuales deberían tener la misma dispersión.</li>
</ol>
<p>2.Residuos vs. el tiempo u otra secuencia: Si los datos fueron tomados de forma
aleatoria no debería verse un patrón definido (Figura
<a href="anova.html#fig:graficos-residuales">5.2</a>-b).</p>
<ol start="3" style="list-style-type: decimal">
<li><p>Gráficos de puntos de los residuos: Este gráfico es similar al primero.
Denuevo, en todos lo niveles del factor los residuales deberían tener la misma
dispersión alrededor del cero(Figura <a href="anova.html#fig:graficos-residuales">5.2</a>-c). Además,
dado que están graficados los residuales estandarizados, cualquier residual
mayor 3 debería ser investigado por ser muy extremo.</p></li>
<li><p>Gráficos de probabilidad normal de los residuos: También llamado gráfico
cuantil-cuantil o <em>qqplot</em> (Figura <a href="anova.html#fig:graficos-residuales">5.2</a>-d). Aquí
se grafican los cuantiles de una normal teórica vs los cuantiles muestrales.
Idealmente, deberían seguir una línea recta de pendiente 1 y ordenada 0.</p></li>
</ol>

<div class="figure"><span id="fig:graficos-residuales"></span>
<img src="anova_files/figure-html/graficos-residuales-1.png" alt="Gráficos de residuales para modelos de ANOVA. a - residuales vs valores predichos. b - residuales vs orden de toma de datos. c - residuales vs niveles del factor. d - gráfico de probabilidad normal." width="100%" />
<p class="caption">
Figura 5.2: Gráficos de residuales para modelos de ANOVA. a - residuales vs valores predichos. b - residuales vs orden de toma de datos. c - residuales vs niveles del factor. d - gráfico de probabilidad normal.
</p>
</div>
<div id="diagnostico-de-los-alejamientos-de-los-supuestos-del-modelo-de-anova" class="section level4">
<h4><span class="header-section-number">5.6.4.1</span> Diagnóstico de los alejamientos de los supuestos del Modelo de ANOVA</h4>
<p><strong>Heterogeneidad de Varianzas</strong>: El Modelo de ANOVA requiere que los términos
del error tengan varianzas constantes para todos los niveles del factor. Cuando
los tamaños de las muestras son iguales o no difieren mucho, esta suposición
puede ser estudiada usando los residuos, los residuos “studentizados” o los
residuos “semistudentizados”. Gráficos de los residuos vs. las medias de los
niveles del factor o los gráficos de puntos de los residuos son útiles. Cuando
los tamaños de las muestras difieren mucho, los residuos “studentizados”
deberían ser usados en estos gráficos. La constancia de la varianza del error se
ve en estos gráficos pues los puntos tienen aproximadamente la misma dispersión
alrededor del cero para cada nivel.</p>
<p>La Figura <a href="anova.html#fig:hetero">5.3</a> muestra un caso en el que las varianzas de los errores no
son constantes. En este caso los términos del error del nivel <em>c</em> del factor
tienen una varianza mayor que los otros dos niveles del factor.</p>

<div class="figure"><span id="fig:hetero"></span>
<img src="anova_files/figure-html/hetero-1.png" alt="Residuales vs Valores Ajustados o predichos. Este gráfico muestra que los residuales uno de los niveles muestra mayor dispersión que el resto de los datos." width="50%" /><img src="anova_files/figure-html/hetero-2.png" alt="Residuales vs Valores Ajustados o predichos. Este gráfico muestra que los residuales uno de los niveles muestra mayor dispersión que el resto de los datos." width="50%" />
<p class="caption">
Figura 5.3: Residuales vs Valores Ajustados o predichos. Este gráfico muestra que los residuales uno de los niveles muestra mayor dispersión que el resto de los datos.
</p>
</div>
<p>Cuando los tamaños de las muestras, para los diferentes niveles del factor son
grandes, los histogramas de los residuos para cada tratamiento, son una manera
efectiva de examinar la constancia de la varianza de los términos del error.</p>
<p><strong>Falta de independencia en los términos del error:</strong> En todos aquellos casos en
que los datos son obtenidos en una secuencia de tiempo, un gráfico de secuencia
de residuos es aconsejable para examinar si los términos del error están
correlacionados. La Figura <a href="anova.html#fig:indpen">5.4</a> muestra un caso en el cual los
residuos aparecen altamente correlacionados. Esto puede pasar porque el operario
tiende a sobreestimar a medida que pasa el tiempo o también porque los equipos
se descalibran.</p>

<div class="figure"><span id="fig:indpen"></span>
<img src="anova_files/figure-html/indpen-1.png" alt="Residuales vs Orden. Los residuales muestran falta de independencia al haber una correlación entre ellos." width="75%" />
<p class="caption">
Figura 5.4: Residuales vs Orden. Los residuales muestran falta de independencia al haber una correlación entre ellos.
</p>
</div>
<p>La siguiente Figura <a href="anova.html#fig:varianza-decrece">5.5</a> muestra un caso donde la varianza decrece con el tiempo.</p>

<div class="figure"><span id="fig:varianza-decrece"></span>
<img src="anova_files/figure-html/varianza-decrece-1.png" alt="Residuales vs Orden. Los residuales muestran que la varianza decrece, ya que al principio son mayores y al final son menores" width="75%" />
<p class="caption">
Figura 5.5: Residuales vs Orden. Los residuales muestran que la varianza decrece, ya que al principio son mayores y al final son menores
</p>
</div>
<p>Cuando los datos son ordenados en alguna a otra secuencia lógica, tal como una
secuencia geográfica, también debe verificarse si existe correlación entre los
términos del error de acuerdo a este orden.</p>
<p><strong>Otros usos del análisis de residuos</strong>: Este tipo de análisis se puede usar
para detectar “outliers”. También es útil para determinar si modelo de ANOVA de
un factor es el adecuado; pues puede determinar la omisión de alguna variable
importante que explica las observaciones. También puede ser usado para
determinar la falta de normalidad de los términos del error. Esto se realiza
graficando los cuantiles de los residuales observados vs los esperados.</p>
</div>
</div>
</div>
<div id="transformaciones" class="section level2">
<h2><span class="header-section-number">5.7</span> Transformaciones</h2>
<div id="transformaciones-para-estabilizar-las-varianzas" class="section level3">
<h3><span class="header-section-number">5.7.1</span> Transformaciones para estabilizar las Varianzas</h3>
<p>Varianza <em>proporcional a</em> <span class="math inline">\(\mu_{i}\)</span> : El estadístico muestral
<span class="math inline">\(\mathbf{S}_\mathbf{i}^\mathbf{2}\mathbf{/}{\overline{\mathbf{Y}}}_{\mathbf{i}}\)</span>
tenderá a ser constante. Este tipo de situaciones a menudo se encuentra cuando
la variable observada es un número entero. Para estos casos, una transformación
raíz cuadrada es útil para estabilizar la varianza:</p>
<p><span class="math inline">\(Y^{&#39;} = \sqrt{Y}\)</span>o <span class="math inline">\(Y^{&#39;} = \sqrt{Y + \frac{1}{2}}\)</span> o<span class="math inline">\(Y^{&#39;} = \sqrt{Y} + \sqrt{Y + 1}\)</span></p>
<p><em>Desviación estándar proporcional a</em> <span class="math inline">\(\mu_{i}\)</span>:
<span class="math inline">\(\mathbf{S}_\mathbf{i}\mathbf{/}\overline{\mathbf{Y}_\mathbf{i}}\)</span>tiende
a ser contante para los diferentes niveles del factor. Una transformación útil
para estabilizar la varianza es la transformación logarítmica:</p>
<p><span class="math inline">\(Y^{&#39;} = \log Y\)</span><em>o</em><span class="math inline">\(Y^{&#39;} = \log{(Y + 1)}\)</span></p>
<p><em>Desviación estándar proporcional a</em> <span class="math inline">\(\mu_{i}^{2}\)</span>:
<span class="math inline">\(\mathbf{S}_\mathbf{i}^{\mathbf{2}}\mathbf{/}\overline{\mathbf{Y}}_{\mathbf{i}}^{\mathbf{2}}\)</span>En
este caso tiende a ser constante. la transformación apropiada es la recíproca:</p>
<p><span class="math display">\[
Y^{&#39;} = \frac{1}{Y}
\]</span></p>
<p><em>La variable dependiente es una proporción</em>: Una transformación apropiada para
este caso es la transformación angular o arcoseno:</p>
<p><span class="math display">\[
Y^{&#39;} = \text{arcsen}\sqrt{Y}
\]</span></p>
</div>
<div id="transformaciones-para-corregir-la-falta-de-normalidad" class="section level3">
<h3><span class="header-section-number">5.7.2</span> Transformaciones para corregir la falta de normalidad</h3>
<p>La transformación que ayuda a corregir la heterogeneidad de varianzas usualmente
también es efectiva para hacer que las distribuciones de los términos del error
sean más normales.</p>
</div>
<div id="efectos-del-alejamiento-de-los-supuestos-del-modelo" class="section level3">
<h3><span class="header-section-number">5.7.3</span> Efectos Del Alejamiento De Los Supuestos Del Modelo</h3>
<div id="normalidad" class="section level4">
<h4><span class="header-section-number">5.7.3.1</span> Normalidad</h4>
<p>Para el modelo I de ANOVA, la falta de normalidad no es importante, en tanto ese
alejamiento no sea extremo. La kurtosis es más importante que la asimetría en
términos de efectos sobre las inferencias (Figura <a href="anova.html#fig:kurtosis">5.6</a>).</p>
<p>La prueba F es poco afectada por la falta de normalidad, ya sea en términos del
nivel de significación o de la potencia de la prueba. Para el Modelo II de
ANOVA, la falta de normalidad tiene serias implicaciones.</p>
<div class="figure"><span id="fig:kurtosis"></span>
<img src="anova_files/figure-html/kurtosis-1.png" alt="Funciones de densidad para curvas asimétrica, mesocúrtica, leptocúrtica, platicúrtica" width="672" />
<p class="caption">
Figura 5.6: Funciones de densidad para curvas asimétrica, mesocúrtica, leptocúrtica, platicúrtica
</p>
</div>
</div>
<div id="heterogeneidad-de-varianzas" class="section level4">
<h4><span class="header-section-number">5.7.3.2</span> Heterogeneidad de varianzas</h4>
<p>Para el modelo de efectos fijos, la prueba de F es ligeramente afectada si los
tamaños muestrales son iguales o no difieren mucho. La prueba de F y los
análisis relacionados son robustos frente a la heterogeneidad de varianzas
cuando los tamaños muestrales son aproximadamente iguales.</p>
<p>Para el modelo de efectos aleatorios, la heterogeneidad de varianzas puede tener
efectos pronunciados sobre las inferencias acerca de los componentes de la
varianza, aun con tamaños muestrales iguales.</p>
</div>
<div id="independencia-de-los-terminos-del-error" class="section level4">
<h4><span class="header-section-number">5.7.3.3</span> Independencia de los términos del error</h4>
<p>La falta de independencia puede tener serios efectos sobre las inferencias en el
análisis de la varianza, para el modelo de efectos fijos y para el de efectos
aleatorios.</p>
</div>
</div>
</div>
<div id="formulacion-del-modelo-i-de-anova." class="section level2">
<h2><span class="header-section-number">5.8</span> Formulación Del Modelo I De ANOVA.</h2>
<p>Denotaremos por I el número de niveles del factor bajo estudio, y denotaremos
cualquiera de estos niveles por el subíndice <span class="math inline">\(i\ (i\  = \ 1,\ 2,\ \ldots,\
I)\)</span>. El número de casos para el i-ésimo nivel del factor es simbolizado por
<span class="math inline">\(n_{i}\)</span>, y el número total de casos en el estudio es denotado por <span class="math inline">\(N\)</span>,
donde:</p>
<p><span class="math display">\[
N = \sum_{i = 1}^{I}n_{i}
\]</span></p>
<p>Además, <span class="math inline">\(Y_{ij}\)</span> denotará la j-ésima observación para el i-ésimo nivel del
factor. Dado que el número de casos para el i-ésimo nivel del factor es denotado
por <span class="math inline">\(n_{i}\)</span>, tendremos <span class="math inline">\(j\  = \ 1,\ 2,\ \ldots,\ n_{i}\)</span>.</p>
<p>El modelo I de ANOVA se puede plantear como sigue:</p>
<p><span class="math display">\[
y_{ij} = u_{i} + \varepsilon_{ij}
\]</span></p>
<p>donde:</p>
<ul>
<li><p><span class="math inline">\(y_{ij}\)</span> es el valor de la j-ésima observación para el i-ésimo nivel del
factor o tratamiento.</p></li>
<li><p><span class="math inline">\(\mu_{i}\)</span> es un parámetro</p></li>
<li><p><span class="math inline">\(\varepsilon_{ij}\)</span> son variables independientes <span class="math inline">\(N(0,\sigma^{2})\)</span></p></li>
<li><p><span class="math inline">\(i = 1,\ 2,\ldots,I;j = 1,\ 2,\ \ldots,\ n_{i}\)</span></p></li>
</ul>
<div id="caracteristicas-importantes-del-modelo" class="section level3">
<h3><span class="header-section-number">5.8.1</span> Características importantes del modelo</h3>
<p>El valor observado de <span class="math inline">\(Y\)</span> en el j-ésimo ensayo del i-ésimo nivel del factor o
tratamiento es la suma de dos componentes: a) un término constante <span class="math inline">\(\mu_{i}\)</span>,
y b) un término del error aleatorio <span class="math inline">\(\varepsilon_{ij}\)</span>.</p>
<p>Dado que <span class="math inline">\(E\left( \varepsilon_{ij} \right) = 0\)</span>, se sigue que:</p>
<p><span class="math display">\[
E\left( Y_{ij} \right) = \mu_{i}
\]</span></p>
<p>Dado que <span class="math inline">\(\mu_{i}\)</span> es una constante, se sigue que:</p>
<p><span class="math display">\[
V\text{ar}\left( Y_{ij} \right) = V\text{ar}\left( \varepsilon_{ij} \right) = \sigma^{2}
\]</span></p>
<p>Así como cada <span class="math inline">\(\varepsilon_{ij}\)</span> esta normalmente distribuido, también lo está
cada <span class="math inline">\(Y_{ij}\)</span>.</p>
<p>Se asume que los términos del error son independientes</p>
<p>El modelo de ANOVA puede ser re-enunciado como:</p>
<p><span class="math display">\[
Y_{ij}\sim N(\mu_{i},\sigma^{2})
\]</span></p>
</div>
<div id="interpretacion-de-las-medias-de-los-niveles-del-factor" class="section level3">
<h3><span class="header-section-number">5.8.2</span> Interpretación De Las Medias De Los Niveles Del Factor</h3>
<p><strong>Datos observacionales</strong>: la media del nivel del factor <span class="math inline">\(\mu_{i}\)</span> corresponde
a las medias para las diferentes poblaciones del nivel del factor.</p>
<p><strong>Datos Experimentales</strong>: la media del nivel del factor <span class="math inline">\(\mu_{i}\)</span> representa
la media de la respuesta que debería obtenerse si el i-ésimo tratamiento fuera
aplicado a todas las unidades en la población de las unidades experimentales
sobre las cuales se harán las inferencias.</p>
</div>
<div id="ajustando-el-modelo" class="section level3">
<h3><span class="header-section-number">5.8.3</span> Ajustando El Modelo</h3>
<p>Supongamos que tenemos <span class="math inline">\(I\)</span> tratamientos o niveles de un factor y que aplicamos
cada uno de ellos a un grupo de unidades experimentales.Los datos se podrían
consignar de la siguiente forma:</p>
<table>
<colgroup>
<col width="14%" />
<col width="11%" />
<col width="11%" />
<col width="2%" />
<col width="14%" />
<col width="2%" />
<col width="14%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th> Tratamientos</th>
<th><span class="math inline">\(T_{1}\)</span></th>
<th><span class="math inline">\(T_{2}\)</span></th>
<th><span class="math inline">\(\ldots\)</span></th>
<th><span class="math inline">\(T_{i}\)</span></th>
<th><span class="math inline">\(\ldots\)</span></th>
<th><span class="math inline">\(T_{I}\)</span></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td><span class="math inline">\(y_{1\mathbf{1}}\)</span></td>
<td><span class="math inline">\(y_{2\mathbf{1}}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(y_{i1}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(y_{I1}\)</span></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><span class="math inline">\(y_{1\mathbf{2}}\)</span></td>
<td><span class="math inline">\(y_{2\mathbf{2}}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(y_{i2}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(y_{I2}\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\ddots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><span class="math inline">\(y_{1j}\)</span></td>
<td><span class="math inline">\(y_{2j}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(y_{i\mathbf{j}}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(y_{I\mathbf{j}}\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\sum_{j = \mathbf{1}}^{n_{i}}y_{i\mathbf{j}}\)</span></td>
<td><span class="math inline">\(\sum_{j = \mathbf{1}}^{n_{1}}y_{1j}\)</span></td>
<td><span class="math inline">\(\sum_{j = \mathbf{1}}^{n_{2}}y_{2j}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(\sum_{j = \mathbf{1}}^{n_{i}}y_{i\mathbf{j}}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(\sum_{j = \mathbf{1}}^{n_{I}}y_{I\mathbf{j}}\)</span></td>
<td><span class="math inline">\(\sum_{j = \mathbf{1}}^{I}y_{i\mathbf{j}}\)</span></td>
</tr>
<tr class="even">
<td></td>
<td><span class="math inline">\(n_{1}\)</span></td>
<td><span class="math inline">\(n_{2}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(n_{i}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(n_{I}\)</span></td>
<td><span class="math inline">\(\sum_{i = \mathbf{1}}^{I}n_{i} = N\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\overline{y_{i\bullet}}\)</span></td>
<td><span class="math inline">\(\overline{y_{1.}}\)</span></td>
<td><span class="math inline">\(\overline{y_{2.}}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(\overline{y_{i\bullet}}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(\overline{y_{I.}}\)</span></td>
<td><span class="math inline">\(\frac{\sum_{i\mathbf{j}}^{N}y_{i\mathbf{j}}}{N} = \overline{y_{\bullet\bullet}}\)</span></td>
</tr>
<tr class="even">
<td></td>
<td><span class="math inline">\(S_{1}^{2}\)</span></td>
<td><span class="math inline">\(S_{2}^{2}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(S_{i}^{2}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(S_{I}^{2}\)</span></td>
<td></td>
</tr>
</tbody>
</table>
<p>donde</p>
<p><span class="math inline">\(T_{i}\)</span> es el tratamiento o nivel del factor <span class="math inline">\(i\)</span>; con <span class="math inline">\(i\  = \ 1,\ 2,\ldots,I\)</span></p>
<p><span class="math inline">\(y_{ij}\)</span> es la observación sobre la unidad experimental<span class="math inline">\(\ j\)</span> con el
tratamiento <span class="math inline">\(i\)</span>; $ j  =  1,2, , n_{i}$.</p>
<p><span class="math inline">\(N\)</span> tamaño de la muestra</p>
<p><span class="math inline">\({\overline{y}}_{i \bullet}\)</span> es la media muestral de cada
tratamiento.</p>
<p><span class="math inline">\(n_{i}\)</span> es el número de observaciones con el tratamiento <span class="math inline">\(i\)</span></p>
<p><span class="math inline">\({\overline{y}}_{\bullet \bullet}\)</span> es la media total, para todas
las observaciones.</p>
<p><span class="math inline">\(S_{i}^{2}\)</span> es la varianza muestral para el tratamiento <span class="math inline">\(i\)</span></p>
</div>
<div id="estimadores-de-minimos-cuadrados" class="section level3">
<h3><span class="header-section-number">5.8.4</span> Estimadores De Mínimos Cuadrados</h3>
<p>De acuerdo al criterio de mínimos cuadrados la suma de los cuadrados de las
desviaciones de las observaciones alrededor de sus valores esperados puede ser
minimizada con respecto a los parámetros. Para un modelo de ANOVA, tenemos que:</p>
<p><span class="math display">\[
E\left( Y_{ij} \right) = \mu_{i}
\]</span></p>
<p>Así, la cantidad a ser minimizada es:</p>
<p><span class="math display">\[
\sum_{i}^{}{\sum_{j}^{}\left( y_{ij} - \mu_{i} \right)^{2}}
\]</span></p>
<p>Esta expresión se puede escribir como:</p>
<p><span class="math display">\[
\sum_{j}^{}\left( y_{1j} - \mu_{1} \right)^{2} + \sum_{j}^{}\left( y_{2j} - \mu_{2} \right)^{2} + \ldots + \sum_{j}^{}\left( y_{Ij} - \mu_{I} \right)^{2}
\]</span></p>
<p>La media muestral minimiza una suma de desviaciones al cuadrado</p>
<span class="math display" id="eq:minimoscuadrados">\[\begin{equation}
  \hat{\mu_{i}} = \overline{y}_{i\bullet}
  \tag{5.1}
\end{equation}\]</span>
<div id="comentarios" class="section level4">
<h4><span class="header-section-number">5.8.4.1</span> Comentarios</h4>
<ol style="list-style-type: decimal">
<li><p>Los estimadores de mínimos cuadrados <a href="anova.html#eq:minimoscuadrados">(5.1)</a> son también
estimadores de máxima verosimilitud para el error normal
(<span class="math inline">\(\varepsilon_{ij}\)</span>) del modelo de ANOVA.</p></li>
<li><p>Para derivar el estimador de mínimo cuadrados de <span class="math inline">\(u_{i}\)</span> , es necesario
minimizar, con respecto a <span class="math inline">\(u_{i}\)</span>, el i-ésimo componente de la suma de
cuadrados en:</p></li>
</ol>
<p><span class="math display">\[
\sum_{j}^{}\left( y_{ij} - \mu_{i} \right)^{2}
\]</span></p>
<p>Diferenciando con respecto a <span class="math inline">\(\mu_{i}\)</span>, se obtiene:</p>
<p><span class="math display">\[
\frac{\partial\sum_{j}^{}\left( y_{ij} - \mu_{i} \right)^{2}}{\partial\mu_{i}} = \sum_{}^{}{- 2\left( y_{ij} - \mu_{i} \right)}
\]</span></p>
<p>Esta derivada se iguala a cero y se reemplaza el parámetro <span class="math inline">\(\mu_{i}\)</span> por su
estimador:</p>
<p><span class="math display">\[
- 2\sum_{j = 1}^{n_{i}}\left( y_{ij} - \mu_{i} \right) = 0
\]</span></p>
<p><span class="math display">\[
\sum_{j = 1}^{n_{i}}y_{ij} = n_{i}\hat{\mu_{i}}
\]</span></p>
<p><span class="math display">\[
\hat{\mu_{i}} = \overline{Y}_{i\bullet}
\]</span></p>
</div>
</div>
</div>
<div id="particion-de-la-suma-de-cuadrados-total" class="section level2">
<h2><span class="header-section-number">5.9</span> Partición De La Suma De Cuadrados Total</h2>
<p>La variabilidad total de las observaciones <span class="math inline">\(y_{ij}\)</span>, sin usar la
información sobre los niveles del factor, es medida en términos de la desviación
de cada observación <span class="math inline">\(y_{ij}\)</span> alrededor de la media total
<span class="math inline">\({\overline{y}}_{\bullet\bullet}\)</span>:</p>
<p><span class="math display">\[
y_{ij} - {\overline{y}}_{\bullet\bullet}
\]</span></p>
<p>Cuando se utiliza la información sobre los niveles del factor, las desviaciones
son aquellas de cada observación <span class="math inline">\(y_{ij}\)</span> alrededor de su respectiva
media estimada <span class="math inline">\({\overline{y}}_{\text{i}\bullet}\)</span>:</p>
<p><span class="math display">\[
y_{ij} - {\overline{y}}_{\text{i}\bullet}
\]</span></p>
<p>La diferencia entre la desviación total y la desviación anterior refleja la
diferencia entre la media estimada del nivel del factor y la media total:</p>
<p><span class="math display">\[
{(y}_{ij} - {\overline{y}}_{\bullet\bullet}) - (y_{ij} - {\overline{y}}_{i}) = {\overline{y}}_{\text{i}\bullet} - {\overline{y}}_{\bullet\bullet}
\]</span></p>
<p>Así, la desviación total <span class="math inline">\(y_{ij} - {\overline{y}}_{\bullet\bullet}\)</span> puede
ser vista como la suma de dos componentes:</p>
<p>La desviación de la media estimada del nivel del factor alrededor de la media
total.</p>
<p>La desviación de <span class="math inline">\(y_{ij}\)</span> alrededor de la media de su nivel del factor.
Esta desviación es simplemente el residuo <span class="math inline">\(\varepsilon_{ij}\)</span> .</p>
<p>Elevando al cuadrado se obtiene:</p>
<p><span class="math display">\[
\sum_{i}^{}{\sum_{j}^{}\left( y_{ij} - {\overline{y}}_{\bullet\bullet} \right)^{2}} = \sum_{i}^{}{n_{i}\left( {\overline{y}}_{\text{i}\bullet} - {\overline{y}}_{\bullet\bullet} \right)^{2}} + \sum_{i}^{}{\sum_{j}^{}\left( y_{ij} - {\overline{y}}_{\text{i}\bullet} \right)^{2}}
\]</span></p>
<p>El primer miembro de igualdad representa la variabilidad total de las
<span class="math inline">\(y_{ij}\)</span> observaciones y es denotado como la <em>suma de cuadrados total
(</em><span class="math inline">\(SCT\)</span><em>)</em>:</p>
<p><span class="math display">\[
SC_T = \sum_{i}^{}{\sum_{j}^{}\left( y_{ij} - {\overline{y}}_{\bullet\bullet} \right)^{2}}
\]</span></p>
<p>El primer término del segundo miembro de la igualdad será indicado como
<span class="math inline">\(SCE\)</span>, la <em>suma de cuadrados entre</em> tratamientos:</p>
<p><span class="math display">\[
SC_E = \sum_{i}^{}{n_{i}\left( y_{\text{i}\bullet} - {\overline{y}}_{\bullet\bullet} \right)^{2}}
\]</span></p>
<p>El segundo término se indica como <span class="math inline">\(SCD\)</span>, la <em>suma de cuadrados dentro</em> de
tratamientos o la <em>suma de cuadrados del error</em>.</p>
<p><span class="math display">\[
SC_D = \sum_{i}^{}{\sum_{j}^{}\left( y_{ij} - {\overline{y}}_{\text{i}\bullet} \right)^{2}} = \sum_{i}^{}{\sum_{j}^{}\varepsilon_{ij}^{2}}
\]</span></p>
<p>Así, podemos escribir:</p>
<p><span class="math display">\[
SCT\  = \ SCE\  + \ SCD
\]</span></p>
<p>La suma total de los cuadrados para el modelo de análisis de la varianza se
compone en consecuencia de dos partes.</p>
<div id="formulas-computatorias" class="section level3">
<h3><span class="header-section-number">5.9.1</span> Fórmulas computatorias</h3>
<p><span class="math display">\[
\begin{matrix}
SC_T = \sum_{i}^{}{\sum_{j}^{}{y_{ij}^{2} - N{\overline{y}}_{\bullet\bullet}^{2}}} \\
SC_E = \sum_{i}^{}{n_{i}y_{\text{i}\bullet}^{2} - N{\overline{y}}_{\bullet\bullet}^{2}} \\
SC_D = \sum_{i}^{}{\sum_{j}^{}{y_{ij}^{2} - n_{i}{\overline{y}}_{\text{i}\bullet}^{2}}} = SC_T - SC_E \\
\end{matrix}
\]</span></p>
</div>
</div>
<div id="grados-de-libertad" class="section level2">
<h2><span class="header-section-number">5.10</span> Grados De Libertad</h2>
<p>Correspondiendo a la descomposición de la suma de cuadrados total, se puede
obtener los grados de libertad asociados.</p>
<p>La <span class="math inline">\(SCT\)</span> tiene <span class="math inline">\((N -\ 1)\)</span> grados de libertad asociados. Hay en conjunto N
desviaciones <span class="math inline">\(Y_{ij} - {\overline{Y}}_{\bullet\bullet}\)</span> , pero un grado de
libertad se pierde debido a que las desviaciones no son independientes a causa
de que la suma de ellas debe ser cero.</p>
<p><span class="math inline">\(\sum_{i}^{}{\sum_{j}^{}\left(y_{ij} - {\overline{y}}_{\bullet\bullet} \right)} = 0\)</span></p>
<p>La <span class="math inline">\(SCE\)</span> (entre tratamientos) tiene <span class="math inline">\((I -\ 1)\)</span> grados de libertad
asociados. Hay I desviaciones de las medias de los niveles de los factores
<span class="math inline">\({\overline{Y}}_{\text{i}\bullet} - {\overline{Y}}_{\bullet\bullet}\)</span>, pero un grado de
libertad se pierde porque las desviaciones no son independientes a causa de que
la suma pesada debe ser cero. <span class="math inline">\(\sum_{i}^{}{n_{i}\left( y_{\text{i}\bullet} - {\overline{y}}_{\bullet\bullet} \right) = \ 0}\)</span>.</p>
<p>La <span class="math inline">\(SCD\)</span> tiene <span class="math inline">\((N -\ I)\)</span> grados de libertad asociados. Esto puede verse
considerando el componente de la <span class="math inline">\(SCD\)</span> para el i-ésimo nivel del factor:</p>
<p><span class="math display">\[
\sum_{j}^{}\left( y_{ij} - {\overline{y}}_{\text{i}\bullet} \right)^{2}
\]</span></p>
<p>La expresión es equivalente a la suma de cuadrados total considerando sólo el
i-ésimo nivel del factor. Así, hay <span class="math inline">\(n_{i}\  - \ 1\)</span> grados de libertad
asociados con esta suma de cuadrados. De esta forma la <span class="math inline">\(SCD\)</span> es una suma de
sumas de cuadrados, los grados de libertad asociados son la suma de los grados
de libertad de sus términos:</p>
<p><span class="math display">\[
(n_{1}\  - \ 1)\  + \ (n_{2}\  - \ 1)\  + \ \ldots\  + \ (n_{I}\  - \ 1)\  = \ N-\ I
\]</span></p>
<p>Los grados de libertad, al igual que la suma de cuadrados, son aditivos.</p>
</div>
<div id="cuadrados-medios" class="section level2">
<h2><span class="header-section-number">5.11</span> Cuadrados Medios</h2>
<p>Los cuadrados medios se obtienen dividiendo la suma de cuadrados por sus grados
de libertad asociados. Se tiene:</p>
<p><span class="math display">\[
\begin{matrix}
CM_E = \frac{SC_E}{I - 1} \\
 \\
CM_D = \frac{SC_D}{N - I} \\
\end{matrix}
\]</span></p>
<p><span class="math inline">\(CM_E\)</span>, es el cuadrado medio entre los tratamientos.</p>
<p><span class="math inline">\(CM_D\)</span>, es el cuadrado medio dentro de los tratamientos o del error.</p>
<div id="esperanza-de-los-cuadrados-medios" class="section level3">
<h3><span class="header-section-number">5.11.1</span> Esperanza de los Cuadrados Medios</h3>
<p>Los valores esperados del <span class="math inline">\(CM_D\)</span> y <span class="math inline">\(CM_E\)</span> pueden ser vistos como:</p>
<p><span class="math display">\[
E\left( CM_D \right) = \sigma^{2}
\]</span></p>
<span class="math display">\[\begin{equation}
E\left( CM_E \right) = \sigma^{2} + \frac{\sum_{}^{}{n_{i}\left( \mu_{i} - \mu_{\bullet} \right)^{2}}}{I - 1}
  (\#eq:eCM_E)
\end{equation}\]</span>
<p>donde</p>
<p><span class="math display">\[
\mu_{\bullet} = \frac{\sum_{}^{}{n_{i}\mu_{i}}}{N}
\]</span></p>
<ol style="list-style-type: decimal">
<li><p>El <span class="math inline">\(CM_D\)</span> es un estimador insesgado de la varianza del error llamado
<span class="math inline">\(\varepsilon_{ij}\)</span>, tanto si las medias <span class="math inline">\(u_{i}\)</span> son iguales como
si no.</p></li>
<li><p>Cuando todas las medias <span class="math inline">\(\mu_i\)</span> de los niveles del factor son iguales y por lo
tanto iguales a la media pesada <span class="math inline">\(\mu_{\bullet}\)</span>, entonces<span class="math inline">\(\ E(CM_E) = \sigma^{2}\)</span> dado
que el segundo término se vuelve cero. Cuando las medias de los niveles del
factor no son iguales, el <span class="math inline">\(CM_E\)</span> tiende en promedio a ser mayor que el <span class="math inline">\(CM_D\)</span>,
dado que el segundo término de la Ecuación @ref(eq:eCM_E) será positivo. Esto es
intuitivamente razonable, como se ilustra en la figura para cuatro tratamientos.
En la situación planteada se asume que todos los tamaños muestrales son iguales,
o sea<span class="math inline">\(\ n_{i} = n\)</span>. Cuando todos los <span class="math inline">\(\mu_{i}\)</span> son iguales, entonces todos lo
<span class="math inline">\(\overline{Y}_{i\bullet}\)</span> siguen la misma distribución en el muestreo, con
una media<span class="math inline">\(\mu_{c}\)</span> y una varianza <span class="math inline">\(\sigma^{2}/n\)</span>. Cuando las <span class="math inline">\(\mu_{i}\)</span> no son
iguales, por otro lado, las<span class="math inline">\(\ {\overline{Y}}_{\text{i}\bullet}\)</span> siguen diferentes
distribuciones en el muestreo, cada una con la misma variabilidad
<span class="math inline">\(\sigma^{2}/n\)</span> pero centradas sobre medias diferentes <span class="math inline">\(\mu_{i}\)</span>
(Figura <a href="anova.html#fig:distr-normales">5.1</a>).</p></li>
</ol>
<p>En consecuencia, los <span class="math inline">\({\overline{Y}}_{\text{i}\bullet}\)</span> tenderán a diferir unos de
otros tanto si los <span class="math inline">\(\mu_i\)</span> difieren como si son iguales, y en consecuencia la
<span class="math inline">\(SCE\)</span> tenderá a ser mayor cuando las medias de los niveles de los factores
no son las mismas que cuando ellas son iguales. Esta propiedad de la <span class="math inline">\(SCE\)</span>
es utilizada en la construcción de la prueba estadística para determinar si las
medias de los niveles del factor son iguales o no. Si la <span class="math inline">\(SCE\)</span> y la
<span class="math inline">\(SCD\)</span> son de la misma magnitud, esto sugiere que las medias µi de los
niveles del factor son iguales. Si la <span class="math inline">\(SCE\)</span> es substancialmente mayor que la
<span class="math inline">\(SCD\)</span>, esto sugeriría que los <span class="math inline">\(\mu_i\)</span> no son iguales.</p>
</div>
<div id="comentarios-1" class="section level3">
<h3><span class="header-section-number">5.11.2</span> Comentarios</h3>
<ol style="list-style-type: decimal">
<li>Para encontrar el valor esperado del <span class="math inline">\(CM_D\)</span>, se ve que puede ser
expresado como sigue:</li>
</ol>
<p><span class="math display">\[
\begin{matrix}
CM_D\  = \frac{1}{N - I}\sum_{i}^{}{\sum_{j}^{}\left( Y_{ij} - {\overline{Y}}_{\text{i}\bullet} \right)^{2}} \\
 = \frac{1}{N - I}\sum_{i}^{}\left\lbrack \left( n_{i} - 1 \right)\frac{\sum_{j}^{}\left( Y_{ij} - {\overline{Y}}_{\text{i}\bullet} \right)^{2}}{\left( n_{i} - 1 \right)} \right\rbrack \\
\end{matrix}
\]</span></p>
<p>Indicamos la varianza muestral de las observaciones para el i-ésimo nivel del
factor como <span class="math inline">\(s_{i}^{2}\)</span>:</p>
<p><span class="math display">\[
s_{i}^{2} = \frac{\sum_{j}^{}\left( Y_{ij} - {\overline{Y}}_{\text{i}\bullet} \right)^{2}}{n_{i} - 1}
\]</span></p>
<p>Por lo tanto, el <span class="math inline">\(CM_D\)</span> puede ser expresado de la siguiente forma:</p>
<p><span class="math display">\[
CM_D = \frac{1}{N - I}\sum_{i}^{}{\left( n_{i} - 1 \right)s_{i}^{2}}
\]</span></p>
<p>Dado que la varianza muestral es un estimador insesgado de la varianza
poblacional, la cual es <span class="math inline">\(\sigma^{2}\)</span> para todos los niveles del factor, se
obtiene:</p>
<p><span class="math display">\[
\begin{aligned}
E\left( CM_D \right)&amp; = \frac{1}{N - I}\sum_{i}^{}{\left( n_{i} - 1 \right)E\left( s_{i}^{2} \right)} \\
&amp; = \frac{1}{N - I}\sum_{i}^{}{\left( n_{i} - 1 \right)\sigma^{2}} \\
&amp; = \sigma^{2} \\
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Se puede derivar el valor esperado de la <span class="math inline">\(CM_E\)</span> para el caso
especial en que todos los tamaños muestrales ni son los mismos, o sea
<span class="math inline">\(n_i = n\)</span>. El resultado general para este caso especial:</li>
</ol>
<p><span class="math display">\[
E\left( CM_E \right) = \sigma^{2} + \frac{n\sum_{}^{}\left( \mu_{i} - \mu_{\bullet} \right)^{2}}{I - 1}\text{ cuando}\ n_{i} = n
\]</span></p>
<p>De esta forma, cuando todos los tamaños muestrales de los niveles del factor
son <span class="math inline">\(n\)</span>, el <span class="math inline">\(CM_E\)</span> se vuelve:</p>
<p><span class="math display">\[
CM_E = \frac{n\sum_{}^{}\left( {\overline{Y}}_{\text{i}\bullet} -
{\overline{Y}}_{\bullet\bullet} \right)^{2}}{I - 1}\text{ cuando }n_{i} = n
\]</span></p>
<p>Para derivar el <span class="math inline">\(E(CM_D)\)</span>, se considera el modelo:</p>
<p><span class="math display">\[
Y_{ij}\  = \ u_{i}\  + \ \varepsilon_{ij}
\]</span></p>
<p>Promediando el <span class="math inline">\(Y_{ij}\)</span> para el i-ésimo nivel del factor, se
obtiene:</p>
<p><span class="math display">\[
{\overline{Y}}_{i \bullet} = \mu_{i} + {\overline{\varepsilon}}_{i \bullet}
\]</span></p>
<p>donde <span class="math inline">\({\overline{\varepsilon}}_{i \bullet}\)</span> es el promedio de los
<span class="math inline">\(\varepsilon_{ij}\)</span> para el i-ésimo nivel del factor:</p>
<p><span class="math display">\[
{\overline{\varepsilon}}_{\text{i}\bullet} = \frac{\sum_{j}^{}\varepsilon_{ij}}{n}
\]</span></p>
<p>Promediando los <span class="math inline">\(Y_{ij}\)</span> sobre todos los niveles del factor, se
obtiene:</p>
<p><span class="math display">\[
{\overline{Y}}_{\bullet\bullet} = \mu_\bullet + {\overline{\varepsilon}}_{\bullet \bullet}
\]</span></p>
<p>donde <span class="math inline">\(\mu_{\bullet}\)</span> para <span class="math inline">\(n_{i} = n\)</span>:</p>
<p><span class="math display">\[
\mu_{\bullet} = \frac{n\sum_{}^{}\mu_{i}}{\text{nI}} = \frac{\sum_{}^{}\mu_{i}}{I}\text{ donde}\ n_{i} = n
\]</span></p>
<p>y <span class="math inline">\({\overline{\varepsilon}}_{\bullet\bullet}\)</span> es el promedio de todos los
<span class="math inline">\(\varepsilon_{ij}\)</span> :</p>
<p><span class="math display">\[
{\overline{\varepsilon}}_{\bullet\bullet} = \frac{\sum_{}^{}{\sum_{}^{}\varepsilon_{ij}}}{\text{nI}}
\]</span></p>
<p>Cuando los tamaños muestrales son iguales, se tiene:</p>
<p><span class="math display">\[
{\overline{Y}}_{\bullet \bullet} = \frac{\sum_{}^{}Y_{\text{i}\bullet}}{I}\ \ \ \ {\overline{\varepsilon}}_{\bullet \bullet} = \frac{\sum_{}^{}\varepsilon_{\text{i}\bullet}}{I}
\]</span></p>
<p>Operando se obtiene:</p>
<p><span class="math display">\[
{\overline{Y}}_{\text{i}\bullet} - {\overline{Y}}_{\bullet \bullet} = \left( \mu_{i} + {\overline{\varepsilon}}_{\text{i}\bullet} \right) - \left( \mu_{\bullet} + {\overline{\varepsilon}}_{\bullet \bullet} \right) = \left( \mu_{i} - \mu_{\bullet} \right) + \left( {\overline{\varepsilon}}_{\text{i}\bullet} - {\overline{\varepsilon}}_{\bullet \bullet} \right)
\]</span></p>
<p>Elevando al cuadrado y sumando sobre los niveles del factor, se obtiene:</p>
<p><span class="math display">\[\sum_{}^{}\left( {\overline{Y}}_{\text{i}\bullet} - {\overline{Y}}_{\bullet \bullet}
\right)^{2} = \sum_{}^{}\left( \mu_{i} - \mu_{\bullet} \right)^{2} +
\sum_{}^{}\left( {\overline{\varepsilon}}_{\text{i}\bullet} -
{\overline{\varepsilon}}_{\bullet \bullet} \right)^{2} + 2\sum_{}^{}\left(
\mu_{i} - \mu_{\bullet \bullet} \right)\left(
{\overline{\varepsilon}}_{\text{i}\bullet} - {\overline{\varepsilon}}_{\bullet
\bullet} \right)\]</span></p>
<p>Se desea encontrar el <span class="math inline">\(E\left\{ \sum_{}^{}\left( {\overline{Y}}_{\text{i}\bullet}  - {\overline{Y}}_{\bullet \bullet} \right)^{2} \right\}\)</span>, y por lo tanto se
necesita encontrar el valor esperado de cada uno de los términos de la
derecha:</p>
<ol start="3" style="list-style-type: decimal">
<li>Dado que <span class="math inline">\(\sum_{}^{}\left( \mu_{i} - \mu_{\bullet} \right)^{2}\)</span> es una
constante, su valor esperado es:</li>
</ol>
<p><span class="math display">\[
E\left\{ \sum_{}^{}\left( \mu_{i} - \mu_{\bullet} \right)^{2} \right\} = \sum_{}^{}\left( \mu_{i} - \mu_{\bullet} \right)^{2}
\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li>Antes de encontrar el valor esperado del segundo término de la derecha,
consideremos la expresión:</li>
</ol>
<p><span class="math display">\[
\frac{\sum_{}^{}\left( {\overline{\varepsilon}}_{\text{i}\bullet} - \overline{\varepsilon}_{\bullet\bullet} \right)^{2}}{I - 1}
\]</span></p>
<p>Esto es una varianza muestral, dado que
<span class="math inline">\({\overline{\varepsilon}}_{\bullet\bullet}\)</span> es la media muestral de los I
términos <span class="math inline">\({\overline{\varepsilon}}_{\text{i}\bullet}\)</span>. Se sabe que la varianza
muestral es un estimador insesgado de la varianza de la variable, en este
caso de <span class="math inline">\({\overline{\varepsilon}}_{\text{i}\bullet}\)</span>. Pero
<span class="math inline">\({\overline{\varepsilon}}_{\text{i}\bullet}\)</span> es la media de n términos
independientes del error <span class="math inline">\(\varepsilon_{ij}\)</span>. Así:</p>
<p><span class="math display">\[
\text{Var}\left( {\overline{\varepsilon}}_{\text{i}\bullet} \right) = \frac{\text{Var}\left( \varepsilon_{ij} \right)}{n} = \frac{\sigma^{2}}{n}
\]</span></p>
<p>Por lo tanto:</p>
<p><span class="math display">\[
E\left\{ \frac{\sum_{}^{}\left( {\overline{\varepsilon}}_{i\bullet} - {\overline{\varepsilon}}_{\bullet\bullet} \right)^{2}}{I - 1} \right\} = \frac{\sigma^{2}}{n}
\]</span></p>
<p>en consecuencia:</p>
<p><span class="math display">\[
E\left\{ \sum_{}^{}\left( {\overline{\varepsilon}}_{\text{i}\bullet} - {\overline{\varepsilon}}_{\bullet \bullet} \right)^{2} \right\} = \frac{\left( I - 1 \right)\sigma^{2}}{n}
\]</span></p>
<ol start="5" style="list-style-type: decimal">
<li>Dado que tanto <span class="math inline">\({\overline{\varepsilon}}_{\text{i}\bullet}\)</span> como
<span class="math inline">\({\overline{\varepsilon}}_{\bullet\bullet}\)</span> son medias de los
<span class="math inline">\(\varepsilon_{ij}\)</span> , los cuales tiene un valor esperado, se sigue
que:</li>
</ol>
<p><span class="math display">\[
E\left( {\overline{\varepsilon}}_{\text{i}\bullet} \right) = 0\ E\left( {\overline{\varepsilon}}_{\bullet \bullet} \right) = 0
\]</span></p>
<p>por tanto:</p>
<p><span class="math display">\[
E\left\{ 2\sum_{}^{}{\left( \mu_{i} - \mu_{\bullet} \right)\left( {\overline{\varepsilon}}_{i\bullet} - {\overline{\varepsilon}}_{\bullet \bullet} \right)} \right\} = 2\sum_{}^{}\left( \mu_{i} - \mu_{\bullet} \right)E\left( {\overline{\varepsilon}}_{\text{i}\bullet} - {\overline{\varepsilon}}_{\bullet \bullet} \right) = 0
\]</span></p>
<p>Ya se ve que:</p>
<p><span class="math display">\[
E\left\{ \sum_{}^{}\left( {\overline{Y}}_{\text{i}\bullet} - {\overline{Y}}_{\bullet\bullet} \right)^{2} \right\} = \sum_{}^{}\left( \mu_{i} - \mu_{\bullet} \right)^{2} + \frac{\left( I - 1 \right)\sigma^{2}}{n}
\]</span></p>
<p>Entonces:</p>
<p><span class="math display">\[
\begin{matrix}
\begin{split}
E\left( CM_E \right)&amp; = E\left\{ \frac{n\sum_{}^{}\left( {\overline{Y}}_{\text{i}\bullet} - {\overline{Y}}_{\bullet \bullet} \right)^{2}}{I - 1} \right\} = \frac{n}{I - 1}\left\lbrack \sum_{}^{}{\left( \mu_{i} - \mu_{\bullet} \right)^{2} + \frac{\left( I - 1 \right)\sigma^{2}}{n}} \right\rbrack \\
&amp; = \sigma^{2} + \frac{n\sum_{}^{}\left( \mu_{i} - \mu_{\bullet} \right)^{2}}{I - 1} \\
\end{split} \\
 \\
\end{matrix}
\]</span></p>
<p>TABLA DE ANÁLISIS DE LA VARIANZA</p>
<p><em>ANOVA de un factor</em></p>
<table>
<colgroup>
<col width="11%" />
<col width="34%" />
<col width="4%" />
<col width="17%" />
<col width="31%" />
</colgroup>
<thead>
<tr class="header">
<th>Fuente de variación</th>
<th>SC</th>
<th>GL</th>
<th>CM</th>
<th>E(CM)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Entre tratamientos</td>
<td><span class="math inline">\({\sum_{i}^{}{n_{i}\left( y_{\text{i}\bullet} - {\overline{y}}_{\bullet\bullet} \right)}}^{2}\)</span></td>
<td><span class="math inline">\(I\  - \ 1\)</span></td>
<td><span class="math inline">\(CM_E = \frac{SC_E}{I - 1}\)</span></td>
<td><span class="math inline">\(\sigma^{2} + \frac{1}{I - 1}\sum_{}^{}n_{i}\left( \mu_{i} - \mu_{\bullet} \right)^{2}\)</span></td>
</tr>
<tr class="even">
<td>Error (dentro de tratamientos)</td>
<td><span class="math inline">\(\sum_{i}^{}{\sum_{j}^{}\left( y_{ij} - {\overline{y}}_{\text{i}\bullet} \right)^{2}}\)</span></td>
<td><span class="math inline">\(N- I\)</span></td>
<td><span class="math inline">\(CM_D = \frac{SC_D}{N - I}\)</span></td>
<td><span class="math inline">\(\sigma^{2}\)</span></td>
</tr>
<tr class="odd">
<td>Total</td>
<td><span class="math inline">\(\sum_{i}^{}{\sum_{j}^{}\left( y_{ij} - {\overline{y}}_{\bullet\bullet} \right)^{2}}\)</span></td>
<td><span class="math inline">\(N - 1\)</span></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="prueba-f-para-la-igualdad-de-las-medias-de-los-niveles-del-factor" class="section level2">
<h2><span class="header-section-number">5.12</span> Prueba F para la Igualdad de las Medias de los Niveles del Factor</h2>
<p>Las conclusiones alternativas a ser consideradas son:</p>
<p><span class="math display">\[
\begin{aligned}
H_{0} &amp;: u_{1} = u_{2} = \ldots = u_{I}\\
H_{a} &amp;: \text{no todos los } \mu_{i}\ \text{son iguales}
\end{aligned}
\]</span></p>
<div id="prueba-estadistica" class="section level3">
<h3><span class="header-section-number">5.12.1</span> Prueba Estadística</h3>
<p>La prueba estadística a ser usada para elegir entre las hipótesis planteadas,
es:</p>
<p><span class="math display">\[
F^{*} = \frac{CM_E}{CM_D}
\]</span></p>
<p>La prueba apropiada es de una cola a la derecha.</p>
</div>
<div id="distribucion-de-mathbffmathbf" class="section level3">
<h3><span class="header-section-number">5.12.2</span> Distribución de <span class="math inline">\(\mathbf{F}^{\mathbf{*}}\)</span></h3>
<p>Cuando todas las medias de los tratamientos son iguales, cada observación
<span class="math inline">\(Y_{ij}\)</span> tiene el mismo valor esperado. En vista de la aditividad de la
suma de cuadrados y de los grados de libertad, del teorema de Cochran se sigue
que:</p>
<p>Cuando <span class="math inline">\(H_{0}\)</span> se verifica, <span class="math inline">\(SCE/\sigma^{2}\)</span> y <span class="math inline">\(SCD/\sigma^{2}\)</span> son
variables distribuidas como <span class="math inline">\(\chi^{2}\)</span> independientes. Por lo tanto: cuando
<span class="math inline">\(H_{0}\)</span> se verifica, <span class="math inline">\(F^{*}\)</span> se distribuye como <span class="math inline">\(F_{\left( I - \ 1 \right)\left( \ N\  - \ I \right)}\)</span>.</p>
<p>Si <span class="math inline">\(H_{a}\)</span> se verifica, esto es, si los <span class="math inline">\(\mu_{i}\)</span> no son todos iguales,
<span class="math inline">\(F^{*}\)</span> no sigue una distribución <span class="math inline">\(F\)</span>. Es más, sigue una distribución
compleja llamada distribución <span class="math inline">\(F_{ no\ central}\)</span>.</p>
</div>
<div id="regla-de-decision" class="section level3">
<h3><span class="header-section-number">5.12.3</span> Regla De Decisión</h3>
<p>Dado que se sabe que <span class="math inline">\(F^{*}\)</span> se distribuye como <span class="math inline">\(F_{\left( I - \ 1 \right)\left( \ N\  - \ I \right)}\)</span>. cuando se verifica <span class="math inline">\(H_{0}\)</span> y que grandes
valores de <span class="math inline">\(F^{*}\)</span> llevan a concluir <span class="math inline">\(H_{a}\)</span> , la regla de decisión para
controlar el nivel de significación <span class="math inline">\(\alpha\)</span> es:</p>
<p>Si <span class="math inline">\(F^{*} \leq F_{(1 - \alpha;I - 1;\ N - I)}\)</span> no se rechaza <span class="math inline">\(H_{0}\)</span>.</p>
<p>Si <span class="math inline">\(F^{*} &gt; F_{(1 - \alpha;I - 1;\ N - I)}\)</span> se rechaza <span class="math inline">\(H_{0}\)</span>.</p>
<p>donde <span class="math inline">\(F^{*} \leq F_{(1 - \alpha;I - 1;\ N - I)}\)</span> es el percentil del <span class="math inline">\(\left( 1 - \alpha \right) \times 100\)</span> de la distribución de <span class="math inline">\(F\)</span>.</p>
</div>
<div id="comentario" class="section level3">
<h3><span class="header-section-number">5.12.4</span> Comentario</h3>
<p>Si hay sólo dos niveles del factor esto es <span class="math inline">\(I = 2\)</span>, se ve fácilmente que la
prueba empleando <span class="math inline">\(F^{*}\)</span> es equivalente a la prueba de “<span class="math inline">\(t\)</span>” a dos colas
para dos poblaciones. La prueba de <span class="math inline">\(F\)</span> tiene <span class="math inline">\((1,\ N - 2)\)</span> grados de
libertad, y la prueba “<span class="math inline">\(t\)</span>” tiene <span class="math inline">\((n_1 + n_2 -2)\)</span> o <span class="math inline">\((N-2)\)</span> grados de
libertad, así ambas pruebas conducen a regiones críticas equivalentes. Para
comparar las medias de dos poblaciones, la prueba de “<span class="math inline">\(t\)</span>” debe preferirse.</p>
</div>
</div>
<div id="formulacion-alternativa-del-modelo-i" class="section level2">
<h2><span class="header-section-number">5.13</span> Formulación Alternativa Del Modelo I</h2>
<p><strong>MODELO I DE ANOVA - MODELO DE LOS EFECTOS DEL FACTOR</strong></p>
<p>Con esta formulación las medias de los tratamientos son expresadas de un modo
equivalente por medio de la identidad:</p>
<p><span class="math display">\[
\mu_{i} \equiv \mu_{\bullet} + \left( \mu_{i} - \mu_{\bullet} \right)
\]</span></p>
<p>donde <span class="math inline">\(u_{\bullet}\)</span> es una constante. Se denotará la diferencia:</p>
<p><span class="math display">\[
(u_{i} - u_{\bullet}) = \alpha_{i}\ 
\]</span></p>
<p>esto implica que:</p>
<p><span class="math inline">\(u_{i} = u_{\bullet} + \alpha_{i}\)</span></p>
<p>La diferencia <span class="math inline">\(u_{i} = u_{\bullet} + \alpha_{i}\)</span> es llamada el efecto del i-ésimo
nivel del factor.</p>
<p>El modelo I de ANOVA puede ser expresado como sigue:</p>
<p><span class="math display">\[
Y_{ij} = u_{\bullet} + \alpha_{i} + \varepsilon_{ij}
\]</span></p>
<p>donde:</p>
<p><span class="math inline">\(u_{\bullet}\)</span> es una componente constante común a todas las observaciones.</p>
<p><span class="math inline">\(\alpha_{i}\)</span> es el efecto del i-ésimo nivel del factor (constante para cada
nivel del factor)</p>
<p><span class="math inline">\(\varepsilon_{ij}\)</span> son variables independientes que se distribuyen
<span class="math inline">\(N(0,\ \sigma^{2})\)</span></p>
<p><span class="math display">\[
i = 1,\ 2,\ldots,\ I;\ j = 1,\ 2,\ldots,\ n_{i}\ 
\]</span></p>
<p>El modelo de ANOVA es llamado el modelo de los efectos del factor pues se
expresa en términos de los efectos del factor <span class="math inline">\(\alpha_{i}\)</span> en distinción del
modelo de las medias de las celdas, el cual se expresa en términos de las medias
de los tratamientos.</p>
<p>El modelo de los efectos del factor es un modelo lineal, como su modelo
equivalente de las medias de las celdas.</p>
<div id="definicion-de-mathbfmu_mathbfbullet" class="section level3">
<h3><span class="header-section-number">5.13.1</span> Definición de <span class="math inline">\(\mathbf{\mu}_{\mathbf{\bullet}}\)</span></h3>
<p><strong>Medias no pesadas:</strong> A menudo, una definición de <span class="math inline">\(\mu_{\bullet}\)</span> como un promedio
no pesado para todas las medias de los niveles del factor <span class="math inline">\(\mu_{i}\)</span> puede ser
útil:</p>
<p><span class="math display">\[
\mu_{\bullet} = \frac{\sum_{i = 1}^{I}\mu_{i}}{I}
\]</span></p>
<p>Esta definición implica que</p>
<p><span class="math display">\[
\sum_{i = 1}^{I}\alpha_{i} = 0
\]</span></p>
<p>pues:</p>
<p><span class="math display">\[
\sum_{}^{}\alpha_{i} = \sum_{}^{}\left( \mu_{i} - \mu_{\bullet} \right) = \sum_{}^{}\mu_{i} - I\mu_{\bullet}
\]</span></p>
<p>y</p>
<p><span class="math display">\[
\sum_{}^{}\mu_{i} = I\mu_{\bullet}
\]</span></p>
<p>Así la definición de la constante general <span class="math inline">\(\text{μ.}\)</span> implica una restricción
sobre los <span class="math inline">\(\mu_{i}\)</span>, en este caso que su suma debe ser cero.</p>
<p><strong>Medias pesadas:</strong> La constante <span class="math inline">\(\text{μ.}\)</span> también puede definirse como un
promedio pesado de las medias de los niveles del factor <span class="math inline">\(\mu_{i}\)</span>:</p>
<p><span class="math display">\[
\mu_{\bullet} = \sum_{i = 1}^{I}{f_{i}\mu_{i}\ }
\]</span></p>
<p>donde los <span class="math inline">\(f_{i}\)</span> son pesos definidos tales que <span class="math inline">\(\sum f_{i} = 1\)</span> La
restricción sobre los <span class="math inline">\(\alpha_{i}\)</span> es entonces:</p>
<p><span class="math display">\[
\sum_{i = 1}^{I}{f_{i}\alpha_{i}\ } = 0
\]</span></p>
<p>La elección de los pesos <span class="math inline">\(f_{i}\)</span> puede depender de la significación de las
medidas resultantes de los efectos de los niveles del factor. Por ejemplo, los
pesos se pueden dar de acuerdo a: a) una medida conocida de importancia o b) de
acuerdo al tamaño muestral.</p>
<p>Cuando los tamaños muestrales son iguales se usa una media no pesada.</p>
</div>
</div>
<div id="prueba-para-la-igualdad-de-las-medias-de-los-niveles-del-factor" class="section level2">
<h2><span class="header-section-number">5.14</span> Prueba Para La Igualdad De Las Medias De Los Niveles Del Factor</h2>
<p>Dado que el modelo de efectos del factor es equivalente al modelo de las medias
de las celdas, la prueba para igualdad de las medias de los niveles del factor
es la misma prueba estadística <span class="math inline">\(F^{*}\)</span>. La única diferencia está en el planteo
de las hipótesis. Para el modelo de las medias de las celdas las hipótesis son:</p>
<p><span class="math display">\[
\begin{aligned}
H_{0} &amp;:\ u_{1} = u_{2} = \ldots = u_{I}\\
H_{a} &amp;:\ \text{no todos los}\ u_{i}\ \text{son iguales}
\end{aligned}
\]</span></p>
<p>Para el modelo de los efectos del factor, estas mismas hipótesis en términos de
los efectos del factor son:</p>
<p><span class="math display">\[
\begin{aligned}
H_{0} &amp;:\ \alpha_{1} = \alpha_{2} = \ldots = \alpha_{I} = 0\\
H_{a} &amp;:\ \text{no todos los}\ \alpha_{i}\ \text{son iguales}
\end{aligned}
\]</span></p>
</div>
<div id="analisis-de-los-efectos-del-nivel-del-factor" class="section level2">
<h2><span class="header-section-number">5.15</span> Análisis De Los Efectos Del Nivel Del Factor</h2>
<p>Si la prueba de F lleva a la conclusión de que las medias de los niveles del
factor µi difieren, se sigue que hay una relación entre el factor y la variable
dependiente. En este caso, un análisis cuidadoso de la naturaleza de los efectos
de los niveles del factor es usualmente emprendido. Esto se hace de dos maneras:</p>
<ol style="list-style-type: decimal">
<li><p>Un análisis directo de los efectos de los niveles de interés del factor
usando técnicas de estimación.</p></li>
<li><p>Pruebas estadísticas con respecto a los efectos de los niveles del factor de
interés.</p></li>
</ol>
<div id="graficos-de-las-estimaciones-de-las-medias-de-los-niveles-del-factor" class="section level3">
<h3><span class="header-section-number">5.15.1</span> Gráficos de las estimaciones de las medias de los niveles del factor</h3>
<p>Se dispone de dos tipos de gráficos (1) una línea, la que es apropiada tanto si
los tamaños de las muestras <span class="math inline">\(n_{i}\)</span> son iguales como si no; y (2) un gráfico
de probabilidad normal, la que es apropiada si los tamaños de las muestras
<span class="math inline">\(n_{i}\)</span> no son iguales.</p>
</div>
<div id="estimacion-de-los-efectos-de-los-niveles-del-factor" class="section level3">
<h3><span class="header-section-number">5.15.2</span> Estimación de los efectos de los niveles del factor</h3>
<p>Las estimaciones de los efectos de los niveles del factor usualmente empleadas
incluyen:</p>
<ol style="list-style-type: decimal">
<li><p>Estimación de la media de un nivel del factor</p></li>
<li><p>Estimación de la diferencia entre dos medias de dos niveles de un factor.</p></li>
<li><p>Estimación de un contraste entre las medias de los niveles del factor.</p></li>
<li><p>Estimación de una combinación lineal de las medias de los niveles del
factor.</p></li>
</ol>
<div id="estimacion-de-la-media-del-nivel-del-factor" class="section level4">
<h4><span class="header-section-number">5.15.2.1</span> Estimación de la media del nivel del factor</h4>
<p>Un estimador insesgado de la media del nivel del factor µi, fue obtenido como:</p>
<p><span class="math display">\[
{\hat{\mu}}_{i} = {\overline{Y}}_{i\bullet}
\]</span></p>
<p>Este estimador tiene media y varianza:</p>
<p><span class="math display">\[
\begin{aligned}
E\left( {\overline{Y}}_{i\bullet} \right) &amp;= \mu_{i} \\
 \\
\text{Var}\left( {\overline{Y}}_{i\bullet} \right) &amp;= \frac{\sigma^{2}}{n_{i}} \\
\end{aligned}
\]</span></p>
<p>El último resultado se sigue pues <span class="math inline">\({\overline{Y}}_{i}. = \mu_{i} + {\overline{\varepsilon}}_{\text{i}\bullet}\)</span>, la suma de una constante a una
media de <span class="math inline">\(n_{i}\)</span> términos independientes <span class="math inline">\(\varepsilon_{ij}\)</span>, cada uno
de los cuales tiene una varianza <span class="math inline">\(\sigma^{2}\)</span>. En consecuencia
<span class="math inline">\({\overline{Y}} _{\text{i}\bullet}\)</span> está normalmente distribuido pues los
términos del error <span class="math inline">\(\varepsilon_{ij}\)</span> son variables aleatorias normales e
independientes.</p>
<p>La varianza estimada de <span class="math inline">\({\overline{Y}}_{\text{i}\bullet}\)</span> se simboliza
<span class="math inline">\(S^{2}({\overline{Y}}_{\text{i}\bullet})\)</span></p>
<p><span class="math display">\[
S^{2} = \frac{CM_D}{n_{i}}
\]</span></p>
<p>Se puede demostrar que <span class="math inline">\(\frac{{\overline{Y}}_{i\bullet} - \mu_{i}}{\sqrt{\frac{CM_D}{n_{i}}}}\)</span>, se distribuye como <span class="math inline">\(t_{N - I}\)</span>.</p>
<p>Se sigue que los límites del intervalo de confianza del <span class="math inline">\((1 - \alpha)\)</span> para
<span class="math inline">\(u_{i}\)</span> son:</p>
<p><span class="math display">\[
{\overline{Y}}_{i\bullet} \pm t_{\left( 1 - \frac{\alpha}{2};N - I \right)}\sqrt{\frac{CM_D}{n_{i}}}
\]</span></p>
</div>
<div id="estimacion-de-la-diferencia-entre-dos-medias-de-niveles-del-factor" class="section level4">
<h4><span class="header-section-number">5.15.2.2</span> Estimación de la diferencia entre dos medias de niveles del factor</h4>
<p>Frecuentemente dos tratamientos o niveles de un factor son comparados por
estimación de la diferencia <em>D</em> entre las dos medias de los niveles del factor,
o sea, <span class="math inline">\(u_{i}\)</span> y <span class="math inline">\(u_{i&#39;}\)</span>:</p>
<p><span class="math display">\[
D = u_{i} - u_{i&#39;}
\]</span></p>
<p>Tal comparación entre dos medias de niveles del factor será llamada comparación
de a pares. Un estimador puntual es:</p>
<p><span class="math display">\[
\overset{\land}{D} = {\overline{Y}}_{\text{i}\bullet} - {\overline{Y}}_{i&#39;\bullet}
\]</span></p>
<p>Este estimador puntual es insesgado:</p>
<p><span class="math display">\[
E\left( \overset{\land}{D} \right) = \mu_{i} - \mu_{i&#39;}
\]</span></p>
<p>Dado que <span class="math inline">\({\overline{Y}}_{\text{i}\bullet}\)</span> y <span class="math inline">\({\overline{Y}}_{i&#39;.}\)</span> son
independientes, la varianza es:</p>
<p><span class="math display">\[
\text{Var}\overset{\land}{\left( D \right)} = Var\left( {\overline{Y}}_{\text{i}\bullet} \right) + Var\left( {\overline{Y}}_{i&#39;.} \right) = \sigma^{2}\left( \frac{1}{n_{i}} + \frac{1}{n_{i&#39;}} \right)
\]</span></p>
<p>La varianza estimada está dada por:</p>
<p><span class="math display">\[
S^{2}\left( \overset{\land}{D} \right) = CM_D\left( \frac{1}{n_{i}} + \frac{1}{n_{i&#39;}} \right)
\]</span></p>
<p><span class="math inline">\(\overset{\land}{D}\)</span> está normalmente distribuido por ser una combinación
lineal de variables independientes normales.</p>
<p>Se sigue, de estas características, que:</p>
<p><span class="math inline">\(\frac{\overset{\land}{D} - D}{S\left( \overset{\land}{D} \right)}\sim t_{N - I}\)</span> para el modelo de ANOVA</p>
<p>De esta manera un intervalo de confianza de <span class="math inline">\((1 - \alpha)\)</span> para <span class="math inline">\(D\)</span> está
dado por:</p>
<p><span class="math display">\[
\overset{\land}{D} \pm t_{\left( 1 - \frac{\alpha}{2};N - I \right)}\sqrt{CM_D\left( \frac{1}{n_{i}} + \frac{1}{n_{i&#39;}} \right)}
\]</span></p>
</div>
<div id="estimacion-de-contrastes" class="section level4">
<h4><span class="header-section-number">5.15.2.3</span> Estimación de contrastes</h4>
<p>Un contraste es una comparación que involucra a dos o más medias e incluye al
caso anterior de comparación de la diferencia entre un par de medias. Un
contraste se simboliza como f y es una combinación lineal de las medias de los
niveles del factor µi donde los coeficientes ci suman cero:</p>
<p><span class="math display">\[
f = \sum_{i = 1}^{I}c_{i}\mu_{i}\text{ donde}\sum_{i = 1}^{I}c_{i} = 0
\]</span></p>
<p><strong>Ejemplos</strong>: Supongamos que estamos estudiando 4 niveles de un factor</p>
<p><span class="math inline">\(f = \mu_{1} - \mu_{2}\)</span>; aquí <span class="math inline">\(c_{1} = 1\)</span>; <span class="math inline">\(c_{2} = - 1\)</span>; <span class="math inline">\(c_{3} = 0\)</span> y
<span class="math inline">\(c_{4} = 0\)</span>; y <span class="math inline">\(\sum_{i = 1}^{4}c_{i} = 0\)</span>.</p>
<p><span class="math inline">\(f = \frac{\mu_{1} + \mu_{2}}{2} - \frac{\mu_{3} + \mu_{4}}{2}\)</span>; aquí <span class="math inline">\(c_{1}\
= \frac{1}{2}\)</span>; <span class="math inline">\(c_{2} = \frac{1}{2}\)</span>; <span class="math inline">\(c_{3} = - \frac{1}{2}\)</span> y <span class="math inline">\(c_{4} = - \frac{1}{2}\)</span>; y <span class="math inline">\(\sum_{i = 1}^{4}c_{i} = 0\)</span>.</p>
<p><span class="math inline">\(f = \frac{\mu_{1} + \mu_{3}}{2} - \frac{\mu_{2} + \mu_{4}}{2}\)</span>; aquí <span class="math inline">\(c_{1} = \frac{1}{2}\)</span>; c2 = -1/2; <span class="math inline">\(c_{3} = \frac{1}{2}\)</span> y <span class="math inline">\(c_{4} = - \frac{1}{2}\)</span>;
y <span class="math inline">\(\sum_{i = 1}^{4}c_{i} = 0\)</span>.</p>
<p>Un estimador insesgado de un contraste <span class="math inline">\(f\)</span> es:</p>
<p><span class="math display">\[
\overset{\land}{f} = \sum_{i = 1}^{I}c_{i}{\overline{Y}}_{\text{i}\bullet}
\]</span></p>
<p>Dado que los <span class="math inline">\({\overline{Y}}_{\text{i}\bullet}\)</span> son independientes, la varianza de
<span class="math inline">\(\overset{\land}{f}\)</span> es:</p>
<p><span class="math display">\[
\text{Var}\left( \overset{\land}{f} \right) = \sum_{i = 1}^{I}c_{i}^{2}\text{Var}\left( {\overline{Y}}_{i} \right) = \sum_{i = 1}^{I}c_{i}^{2}\left( \frac{\sigma^{2}}{n_{i}} \right) = \sigma^{2}\sum_{i = 1}^{I}\frac{c_{i}^{2}}{n_{i}}
\]</span></p>
<p>Un estimador insesgado de esta varianza es:</p>
<p><span class="math display">\[
S^{2}\left( \overset{\land}{f} \right) = CM_D\sum_{i = 1}^{I}\frac{c_{i}^{2}}{n_{i}}
\]</span></p>
<p><span class="math inline">\(\overset{\land}{f}\)</span> está normalmente distribuida pues es una combinación
lineal de variables independientes normalmente distribuidas. Se puede demostrar
que:</p>
<p><span class="math inline">\(\frac{\overset{\land}{f} - f}{\sqrt{CM_D\sum_{i = 1}^{I}\frac{c_{i}^{2}}{n_{i}}}}\sim t_{\left( N - I \right)}\)</span> para el modelo de
ANOVA</p>
</div>
</div>
<div id="comparaciones-multiples" class="section level3">
<h3><span class="header-section-number">5.15.3</span> Comparaciones múltiples</h3>
<ol style="list-style-type: decimal">
<li><p>Planeados o A Priori: Se proponen antes de ver los resultados del
experimento, pueden ser significativos aunque el ANOVA no dé significativo.</p></li>
<li><p>No Planeados o A Posteriori: Se plantean a la vista de los resultados, se
hacen sólo si el ANOVA da significativo.</p></li>
</ol>
<div id="planeados" class="section level4">
<h4><span class="header-section-number">5.15.3.1</span> Planeados</h4>
<ol style="list-style-type: decimal">
<li><em>LSD</em>: el criterio de la prueba para examinar si existen diferencias
significativas entre medias se llama diferencia mínima significativa y se
simboliza <span class="math inline">\(\text{LSD}\)</span>:</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\text{LSD}_{\alpha}&amp; = t_{\left( \alpha\left( 2 \right);N - I \right)}\sqrt{CM_D\left( \frac{1}{n_{i}} + \frac{1}{n_{i^{&#39;}}} \right)} \\
&amp; = t_{\left( \alpha\left( 2 \right);N - I \right)}\sqrt{CM_D\left( \frac{2}{n} \right)}\text{ para }n_{i} = n\ \forall\ i \\
\end{aligned}
\]</span></p>
<p>Se calcula<span class="math inline">\(\left| {\overline{Y}}_{\text{i}\bullet} - {\overline{Y}}_{i&#39;.} \right|\)</span> y
este valor se compara con <span class="math inline">\(\text{LSD}\)</span>, en caso de que el primero sea mayor
las diferencias son significativas.</p>
<ol start="2" style="list-style-type: decimal">
<li><em>Método de Bonferroni o método “t”</em>: Este método es aplicable ya sea que los
tamaños muestrales sean iguales o no; o si se hacen comparaciones de a pares o
contrastes.</li>
</ol>
<ul>
<li>Un contraste</li>
</ul>
<p><span class="math display">\[
f = \sum_{i = 1}^{I}{c_{i}\mu_{i\bullet}}
\]</span></p>
<p>estimo por medio de</p>
<p><span class="math display">\[
\overset{\land}{f} = \sum_{i = 1}^{I}{c_{i}{\overline{y}}_{i\bullet}}
\]</span></p>
<p><span class="math display">\[
H_{0f}:\ f = 0
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\text{Var}\left( \overset{\land}{f} \right) &amp;= \text{Var}\left( \sum_{}^{}{c_{i}{\overline{y}}_{i\bullet}} \right) \\
 &amp;= \sum_{}^{}c_{i}^{2}\text{Var}\left( {\overline{y}}_{i\bullet} \right) \\
 &amp;= \sum_{}^{}c_{i}^{2}\frac{\overset{\land}{\sigma^{2}}}{n} \\
 &amp;= \overset{\land}{\sigma^{2}}\sum_{i}^{}\frac{c_{i}^{2}}{n_{i}} \\
 &amp;= CM_D\sum_{i}^{}\frac{c_{i}^{2}}{n_{i}} \\
 \Rightarrow \text{ES}\left( \overset{\land}{f} \right) &amp;= \sqrt{CM_D\sum_{i}^{}\frac{c_{i}^{2}}{n_{i}}} \\
\end{aligned}
\]</span></p>
<ul>
<li>Intervalo de confianza</li>
</ul>
<p><span class="math display">\[
\begin{matrix}
\overset{\land}{f} \pm t_{\alpha(2);N - I}\sqrt{CM_D\sum_{i}^{}\frac{c_{i}^{2}}{n_{i}}} \\
\text{Si}\ 0 \in \left\lbrack \ \right\rbrack \Rightarrow no\ rechazo\ H_{0} \\
\varepsilon = \frac{\overset{\land}{f}}{\sqrt{CM_D\sum_{i}^{}\frac{c_{i}^{2}}{n_{i}}}} \\
\text{VC} = t_{\alpha(2);N - I} \\
\text{Si }\varepsilon &gt; \text{VC} \Rightarrow rechazo\ H_{0} \\
\end{matrix}
\]</span></p>
<ul>
<li><span class="math inline">\(m\)</span> contrastes <span class="math inline">\(f_{1},\ f_{2},\ \ldots,\ f_{m}\)</span></li>
</ul>
<p>Se fija el número de contrastes a realizarse, junto con el experimento, <em>m</em>
contrastes. Se toma como nivel para cada contraste <span class="math inline">\(\frac{\alpha}{m} = \alpha_{i} \Rightarrow \sum_{i}^{}\alpha_{i} = \alpha\)</span>.</p>
<ul>
<li>Intervalo de confianza</li>
</ul>
<p><span class="math display">\[
{\overset{\land}{f}}_{i} \pm t_{\frac{\alpha}{m}(2);N - I}\sqrt{CM_D\sum_{i}^{}\frac{c_{i}^{2}}{n_{i}}}
\]</span></p>
</div>
<div id="no-planeados" class="section level4">
<h4><span class="header-section-number">5.15.3.2</span> No Planeados:</h4>
<ol style="list-style-type: decimal">
<li><em>Método de Scheffé</em>: Este método da, para cada contraste, intervalos de
confianza de la forma:</li>
</ol>
<p><span class="math display">\[
\overset{\land}{f} \pm \text{VC}\ \text{ES}\left( \overset{\land}{f} \right)
\]</span></p>
<p>donde</p>
<p><span class="math display">\[
\begin{matrix}
\overset{\land}{f} = \sum_{i}^{}{c_{i}{\overline{y}}_{i\bullet}} \\
\text{VC} = \sqrt{\left( I - 1 \right)F_{I - 1;N - I;\alpha}} = S \\
\text{ES}\left( \overset{\land}{f} \right) = \sqrt{CM_D\sum_{i}^{}\frac{c_{\ _{i}}^{2}}{n_{i}}} \\
\end{matrix}
\]</span></p>
<p>Si usamos el estadístico</p>
<p><span class="math inline">\(\varepsilon = \frac{\overset{\land}{f}}{\text{ES}\left( \overset{\land}{f} \right)}\)</span> rechazo <span class="math inline">\(H_{0}\)</span> sí <span class="math inline">\(\varepsilon &gt; S\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li><em>Método de Tukey</em></li>
</ol>
<p>Utiliza el método de rangos <em>studentizado</em>. Supongamos que se tiene <span class="math inline">\(r\)</span>
observaciones independientes <span class="math inline">\(Y_{1},\ \ldots,\ Y_{r}\)</span> de una distribución
normal con media <span class="math inline">\(u\)</span> y varianza <span class="math inline">\(\sigma^{2}\)</span>. Llamamos w al rango de estas
observaciones; así:</p>
<p><span class="math display">\[
w = max(Y_{i}) - min(Y_{i})
\]</span></p>
<p>Supongamos que se tiene una estimación <span class="math inline">\(S^{2}\)</span> de la varianza <span class="math inline">\(\sigma^{2}\)</span>
la cual está basada sobre ν grados de libertad. El cociente <span class="math inline">\(w/s\)</span> es llamado
<em>rango studentizado</em> y se denota:</p>
<p><span class="math display">\[
q\left( r,\nu \right) = \frac{w}{S}
\]</span></p>
<p><span class="math display">\[
\begin{matrix}
\varepsilon = \frac{{\overline{y}}_{\text{i}\bullet\text{max}} - {\overline{y}}_{\text{i}\bullet\text{min}}}{S_{{\overline{y}}_{\bullet\bullet}}}\sim q_{I;N - I} \\
S_{{\overline{y}}_{\bullet\bullet}} = \sqrt{\frac{CM_D}{n}} \\
\end{matrix}
\]</span></p>
<p>Sólo se puede usar si los <span class="math inline">\(n = n_{i}\ \forall\text{\ i}\)</span>. Si <span class="math inline">\(\text{n\ } \neq \ n_{i}\)</span> se usa <span class="math inline">\(n = min(n_{i}\ ,\ n_{j})\)</span></p>
<p>Si el <span class="math inline">\(\varepsilon &gt; q_{I;N - I;\alpha\ }\)</span>, rechazo <span class="math inline">\(H_{0}\)</span>.</p>
</div>
<div id="ni-planeados-ni-no-planeados" class="section level4">
<h4><span class="header-section-number">5.15.3.3</span> Ni planeados ni no planeados</h4>
<p>Contrastes Ortogonales: son contrastes tales que:</p>
<span class="math display">\[\begin{equation}
\begin{aligned} 
f = \sum{c_{i}\mu_{i}}\\ 
 \sum {c_{i}} &amp;= 0 \\
 \sum{c_{i}^{j}c_{i}^{j&#39;}} &amp;= 0\ \forall j \neq j&#39;
\end{aligned}
\end{equation}\]</span>
<p>donde <span class="math inline">\(j\)</span> y <span class="math inline">\(j&#39;\)</span> son contrastes diferentes.</p>
<p>Para aplicar estos contrastes se supone que los <span class="math inline">\(n_{i} = n\ \forall i\)</span>
; y que el número de contrastes ortogonales es el mismo que los grados de
libertad entre, es decir el número de tratamientos menos uno.</p>
<p><em>Ejemplo:</em></p>
<p>Supongamos que tenemos cuatro niveles de un factor</p>
<table>
<thead>
<tr class="header">
<th>T1</th>
<th>T2</th>
<th>T3</th>
<th>T4</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>Entonces sólo se pueden hacer 3 contrastes. Sean, por ejemplo:</p>
<p><span class="math display">\[
\begin{aligned}
f_{1} &amp;= \mu_{1} - \frac{\mu_{2}}{3} - \frac{\mu_{3}}{3} - \frac{\mu_{4}}{3} \\
f_{2} &amp;= \mu_{3} - \mu_{4} \\
f_{3} &amp;= \mu_{2} - \frac{\mu_{3}}{2} - \frac{\mu_{4}}{2} \\
c_{1} &amp;= \begin{pmatrix}
1 &amp; - \frac{1}{3} &amp; - \frac{1}{3} &amp; - \frac{1}{3} \\
\end{pmatrix} \\
c_{2} &amp;= \begin{pmatrix}
0 &amp; 0 &amp; 1 &amp; - 1 \\
\end{pmatrix} \\
c_{3} &amp;= \begin{pmatrix}
0 &amp; 1 &amp; - \frac{1}{2} &amp; - \frac{1}{2} \\
\end{pmatrix} \\
\end{aligned}
\]</span></p>
<p>Se puede comprobar que cada uno es un contraste porque <span class="math inline">\(\sum{c_i}=0\)</span> y
si hacemos la multiplicación de a pares se comprueba su ortogonalidad:</p>
<p><span class="math display">\[
\begin{aligned}
\sum{c_i^1c_i^2} &amp;= 1 &amp;\times &amp; 0 &amp; + &amp; -\frac{1}{3} &amp; \times &amp; 0 &amp; + &amp; -\frac{1}{3} &amp;\times &amp; 1            &amp; + &amp; -\frac{1}{3} &amp; \times &amp; -1           &amp;= 0 \\
\sum{c_i^1c_i^3} &amp;= 1 &amp;\times &amp; 0 &amp; + &amp; -\frac{1}{3} &amp; \times &amp; 1 &amp; + &amp; -\frac{1}{3} &amp;\times &amp; -\frac{1}{2} &amp; + &amp; -\frac{1}{3} &amp; \times &amp; -\frac{1}{2} &amp;= 0\\
\sum{c_i^2c_i^3} &amp;= 0 &amp;\times &amp; 0 &amp; + &amp; 0            &amp; \times &amp; 1 &amp; + &amp; 1            &amp;\times &amp; -\frac{1}{2} &amp; + &amp; -1           &amp; \times &amp; -\frac{1}{2} &amp;= 0
\end{aligned}
\]</span></p>
<p>Esto es equivalente a tener una matriz ortogonal de coeficientes. Para estudiar
la significación de los contrastes se debe encontrar un estadístico y compararlo
con algún valor crítico. La idea es descomponer la <span class="math inline">\(SCE\)</span> en <span class="math inline">\(\text{SC}\)</span>
independientes cada un grado de libertad. En el ejemplo la <span class="math inline">\(SCE\)</span> se
descompone en:</p>
<p><span class="math display">\[
SCE\  = \ SC_{1,\ 2,\ 3,\ 4}\  + \ SC_{3,\ 4}\  + \ SC_{2,3,4}
\]</span></p>
<p>El procedimiento para calcular cada una de las sumas de cuadrados es:</p>
<p><span class="math display">\[
\begin{matrix}
SC_{f_{i}} = \frac{{\overset{\land}{f}}_{i}^{2}}{\frac{\sum_{}^{}c_{i}^{2}}{n}} = \frac{{\overset{\land}{f}}_{i}^{2}n}{\sum_{}^{}c_{i}^{2}} \\
\text{donde}\ {\overset{\land}{f}}_{i} = \sum_{}^{}c_{i}{\overline{Y}}_{\text{i}\bullet} \\
\end{matrix}
\]</span></p>
<p>El cociente</p>
<p><span class="math display">\[
\frac{SC_{f_{i}}}{CM_D}\sim F_{\ _{1,N - I;\alpha}}
\]</span></p>
<p><em>Ejemplo 1.- Comparaciones</em></p>
<p>Se midió el contenido de nitrógeno tres suelos.</p>
<pre><code>## 
## Study: nitro_aov ~ &quot;trt&quot;
## 
## LSD t Test for nitro 
## 
## Mean Square Error:  274.3452 
## 
## trt,  means and individual ( 95 %) CI
## 
##     nitro      std r      LCL      UCL Min Max
## A 275.250 20.04816 8 263.0717 287.4283 242 300
## B 293.625 13.79376 8 281.4467 305.8033 282 320
## C 288.625 15.19340 8 276.4467 300.8033 264 314
## 
## Alpha: 0.05 ; DF Error: 21
## Critical Value of t: 2.079614 
## 
## least Significant Difference: 17.22271 
## 
## Treatments with the same letter are not significantly different.
## 
##     nitro groups
## B 293.625      a
## C 288.625     ab
## A 275.250      b</code></pre>
<p>⇒ Existen diferencias entre los sitios A y B en lo que a contenido de nitrógeno
se refiere.</p>
<p><em>Ejemplo 2.- Comparaciones a posteriori</em></p>
<div class="figure"><span id="fig:ratas-posteriori"></span>
<img src="anova_files/figure-html/ratas-posteriori-1.png" alt="Presion de cuatro especies de ratas. media +- error estándar, n = 10." width="75%" />
<p class="caption">
Figura 5.7: Presion de cuatro especies de ratas. media +- error estándar, n = 10.
</p>
</div>
<p><strong>Test de Sheffé</strong></p>
<pre><code>## 
## Study: ratas_aov ~ &quot;especie&quot;
## 
## Scheffe Test for presion 
## 
## Mean Square Error  : 9.25 
## 
## especie,  means
## 
##   presion      std  r Min Max
## A    84.5 3.922867 10  79  92
## B    88.0 2.748737 10  84  92
## C    91.1 2.378141 10  87  95
## D    88.8 2.898275 10  85  93
## 
## Alpha: 0.05 ; DF Error: 36 
## Critical Value of F: 2.866266 
## 
## Minimum Significant Difference: 3.988455 
## 
## Means with the same letter are not significantly different.
## 
##   presion groups
## C    91.1      a
## D    88.8      a
## B    88.0     ab
## A    84.5      b</code></pre>
<p><strong>Test de Tukey</strong></p>
<pre><code>## 
## Study: ratas_aov ~ &quot;especie&quot;
## 
## HSD Test for presion 
## 
## Mean Square Error:  9.25 
## 
## especie,  means
## 
##   presion      std  r Min Max
## A    84.5 3.922867 10  79  92
## B    88.0 2.748737 10  84  92
## C    91.1 2.378141 10  87  95
## D    88.8 2.898275 10  85  93
## 
## Alpha: 0.05 ; DF Error: 36 
## Critical Value of Studentized Range: 3.808798 
## 
## Minimun Significant Difference: 3.663185 
## 
## Treatments with the same letter are not significantly different.
## 
##   presion groups
## C    91.1      a
## D    88.8      a
## B    88.0     ab
## A    84.5      b</code></pre>
<p><strong>Polinomios ortogonales</strong></p>
<table style="width:96%;">
<colgroup>
<col width="33%" />
<col width="6%" />
<col width="12%" />
<col width="13%" />
<col width="13%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Df</th>
<th align="center">Sum Sq</th>
<th align="center">Mean Sq</th>
<th align="center">F value</th>
<th align="center">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>especie</strong></td>
<td align="center">3</td>
<td align="center">224.6</td>
<td align="center">74.87</td>
<td align="center">8.094</td>
<td align="center">0.0003005</td>
</tr>
<tr class="even">
<td align="center"><strong>especie: A vs C-D</strong></td>
<td align="center">1</td>
<td align="center">198</td>
<td align="center">198</td>
<td align="center">21.41</td>
<td align="center">4.672e-05</td>
</tr>
<tr class="odd">
<td align="center"><strong>especie: A vs B</strong></td>
<td align="center">1</td>
<td align="center">0.1333</td>
<td align="center">0.1333</td>
<td align="center">0.01441</td>
<td align="center">0.9051</td>
</tr>
<tr class="even">
<td align="center"><strong>especie: C vs D</strong></td>
<td align="center">1</td>
<td align="center">26.45</td>
<td align="center">26.45</td>
<td align="center">2.859</td>
<td align="center">0.09948</td>
</tr>
<tr class="odd">
<td align="center"><strong>Residuals</strong></td>
<td align="center">36</td>
<td align="center">333</td>
<td align="center">9.25</td>
<td align="center">NA</td>
<td align="center">NA</td>
</tr>
</tbody>
</table>
<p>Tabla: Modelo de Análisis de la Varianza
Existen diferencias entre A vs C –D y no existen entre C y D.</p>
<p><em>Ejercicio:</em> Comprobar si los contrastes son ortogonales.</p>
<p><strong>Prueba de homogeneidad de varianzas</strong></p>
<table style="width:51%;">
<colgroup>
<col width="16%" />
<col width="6%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Df</th>
<th align="center">F value</th>
<th align="center">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>group</strong></td>
<td align="center">3</td>
<td align="center">0.7086</td>
<td align="center">0.5532</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center">36</td>
<td align="center">NA</td>
<td align="center">NA</td>
</tr>
</tbody>
</table>
<p>Tabla: Prueba de Levene para homogeneidad de varianzas (centro = mediana).</p>
<table style="width:71%;">
<colgroup>
<col width="22%" />
<col width="12%" />
<col width="6%" />
<col width="13%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Sum Sq</th>
<th align="center">Df</th>
<th align="center">F value</th>
<th align="center">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>especie</strong></td>
<td align="center">224.6</td>
<td align="center">3</td>
<td align="center">8.094</td>
<td align="center">0.0003005</td>
</tr>
<tr class="even">
<td align="center"><strong>Residuals</strong></td>
<td align="center">333</td>
<td align="center">36</td>
<td align="center">NA</td>
<td align="center">NA</td>
</tr>
</tbody>
</table>
<p>Tabla: ANOVA (Tipo II)</p>
<p><strong>Medias marginales estimadas</strong></p>
<table style="width:76%;">
<colgroup>
<col width="13%" />
<col width="12%" />
<col width="12%" />
<col width="6%" />
<col width="15%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">especie</th>
<th align="center">lsmean</th>
<th align="center">SE</th>
<th align="center">df</th>
<th align="center">lower.CL</th>
<th align="center">upper.CL</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">A</td>
<td align="center">84.5</td>
<td align="center">0.9618</td>
<td align="center">36</td>
<td align="center">82.55</td>
<td align="center">86.45</td>
</tr>
<tr class="even">
<td align="center">B</td>
<td align="center">88</td>
<td align="center">0.9618</td>
<td align="center">36</td>
<td align="center">86.05</td>
<td align="center">89.95</td>
</tr>
<tr class="odd">
<td align="center">C</td>
<td align="center">91.1</td>
<td align="center">0.9618</td>
<td align="center">36</td>
<td align="center">89.15</td>
<td align="center">93.05</td>
</tr>
<tr class="even">
<td align="center">D</td>
<td align="center">88.8</td>
<td align="center">0.9618</td>
<td align="center">36</td>
<td align="center">86.85</td>
<td align="center">90.75</td>
</tr>
</tbody>
</table>
<p><strong>Pruebas post hoc</strong></p>
<table style="width:100%;">
<colgroup>
<col width="20%" />
<col width="14%" />
<col width="13%" />
<col width="11%" />
<col width="10%" />
<col width="14%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Prueba</th>
<th align="center">contrast</th>
<th align="center">estimate</th>
<th align="center">SE</th>
<th align="center">df</th>
<th align="center">t.ratio</th>
<th align="center">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Tukey</td>
<td align="center">A - B</td>
<td align="center">-3.5</td>
<td align="center">1.4</td>
<td align="center">36</td>
<td align="center">-2.57</td>
<td align="center">0.06553</td>
</tr>
<tr class="even">
<td align="center"><strong>Tukey</strong></td>
<td align="center"><strong>A - C</strong></td>
<td align="center"><strong>-6.6</strong></td>
<td align="center"><strong>1.4</strong></td>
<td align="center"><strong>36</strong></td>
<td align="center"><strong>-4.85</strong></td>
<td align="center"><strong>0.00013</strong></td>
</tr>
<tr class="odd">
<td align="center"><strong>Tukey</strong></td>
<td align="center"><strong>A - D</strong></td>
<td align="center"><strong>-4.3</strong></td>
<td align="center"><strong>1.4</strong></td>
<td align="center"><strong>36</strong></td>
<td align="center"><strong>-3.16</strong></td>
<td align="center"><strong>0.01606</strong></td>
</tr>
<tr class="even">
<td align="center">Tukey</td>
<td align="center">B - C</td>
<td align="center">-3.1</td>
<td align="center">1.4</td>
<td align="center">36</td>
<td align="center">-2.28</td>
<td align="center">0.12197</td>
</tr>
<tr class="odd">
<td align="center">Tukey</td>
<td align="center">B - D</td>
<td align="center">-0.8</td>
<td align="center">1.4</td>
<td align="center">36</td>
<td align="center">-0.59</td>
<td align="center">0.93501</td>
</tr>
<tr class="even">
<td align="center">Tukey</td>
<td align="center">C - D</td>
<td align="center">2.3</td>
<td align="center">1.4</td>
<td align="center">36</td>
<td align="center">1.69</td>
<td align="center">0.34314</td>
</tr>
<tr class="odd">
<td align="center">Bonferroni</td>
<td align="center">A - B</td>
<td align="center">-3.5</td>
<td align="center">1.4</td>
<td align="center">36</td>
<td align="center">-2.57</td>
<td align="center">0.08604</td>
</tr>
<tr class="even">
<td align="center"><strong>Bonferroni</strong></td>
<td align="center"><strong>A - C</strong></td>
<td align="center"><strong>-6.6</strong></td>
<td align="center"><strong>1.4</strong></td>
<td align="center"><strong>36</strong></td>
<td align="center"><strong>-4.85</strong></td>
<td align="center"><strong>0.00014</strong></td>
</tr>
<tr class="odd">
<td align="center"><strong>Bonferroni</strong></td>
<td align="center"><strong>A - D</strong></td>
<td align="center"><strong>-4.3</strong></td>
<td align="center"><strong>1.4</strong></td>
<td align="center"><strong>36</strong></td>
<td align="center"><strong>-3.16</strong></td>
<td align="center"><strong>0.01908</strong></td>
</tr>
<tr class="even">
<td align="center">Bonferroni</td>
<td align="center">B - C</td>
<td align="center">-3.1</td>
<td align="center">1.4</td>
<td align="center">36</td>
<td align="center">-2.28</td>
<td align="center">0.17213</td>
</tr>
<tr class="odd">
<td align="center">Bonferroni</td>
<td align="center">B - D</td>
<td align="center">-0.8</td>
<td align="center">1.4</td>
<td align="center">36</td>
<td align="center">-0.59</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">Bonferroni</td>
<td align="center">C - D</td>
<td align="center">2.3</td>
<td align="center">1.4</td>
<td align="center">36</td>
<td align="center">1.69</td>
<td align="center">0.59688</td>
</tr>
<tr class="odd">
<td align="center"><strong>LSD</strong></td>
<td align="center"><strong>A - B</strong></td>
<td align="center"><strong>-3.5</strong></td>
<td align="center"><strong>1.4</strong></td>
<td align="center"><strong>36</strong></td>
<td align="center"><strong>-2.57</strong></td>
<td align="center"><strong>0.01434</strong></td>
</tr>
<tr class="even">
<td align="center"><strong>LSD</strong></td>
<td align="center"><strong>A - C</strong></td>
<td align="center"><strong>-6.6</strong></td>
<td align="center"><strong>1.4</strong></td>
<td align="center"><strong>36</strong></td>
<td align="center"><strong>-4.85</strong></td>
<td align="center"><strong>2e-05</strong></td>
</tr>
<tr class="odd">
<td align="center"><strong>LSD</strong></td>
<td align="center"><strong>A - D</strong></td>
<td align="center"><strong>-4.3</strong></td>
<td align="center"><strong>1.4</strong></td>
<td align="center"><strong>36</strong></td>
<td align="center"><strong>-3.16</strong></td>
<td align="center"><strong>0.00318</strong></td>
</tr>
<tr class="even">
<td align="center"><strong>LSD</strong></td>
<td align="center"><strong>B - C</strong></td>
<td align="center"><strong>-3.1</strong></td>
<td align="center"><strong>1.4</strong></td>
<td align="center"><strong>36</strong></td>
<td align="center"><strong>-2.28</strong></td>
<td align="center"><strong>0.02869</strong></td>
</tr>
<tr class="odd">
<td align="center">LSD</td>
<td align="center">B - D</td>
<td align="center">-0.8</td>
<td align="center">1.4</td>
<td align="center">36</td>
<td align="center">-0.59</td>
<td align="center">0.56009</td>
</tr>
<tr class="even">
<td align="center">LSD</td>
<td align="center">C - D</td>
<td align="center">2.3</td>
<td align="center">1.4</td>
<td align="center">36</td>
<td align="center">1.69</td>
<td align="center">0.09948</td>
</tr>
<tr class="odd">
<td align="center">Scheffe</td>
<td align="center">A - B</td>
<td align="center">-3.5</td>
<td align="center">NA</td>
<td align="center">NA</td>
<td align="center">NA</td>
<td align="center">0.1041</td>
</tr>
<tr class="even">
<td align="center"><strong>Scheffe</strong></td>
<td align="center"><strong>A - C</strong></td>
<td align="center"><strong>-6.6</strong></td>
<td align="center">NA</td>
<td align="center">NA</td>
<td align="center">NA</td>
<td align="center"><strong>4e-04</strong></td>
</tr>
<tr class="odd">
<td align="center"><strong>Scheffe</strong></td>
<td align="center"><strong>A - D</strong></td>
<td align="center"><strong>-4.3</strong></td>
<td align="center">NA</td>
<td align="center">NA</td>
<td align="center">NA</td>
<td align="center"><strong>0.0301</strong></td>
</tr>
<tr class="even">
<td align="center">Scheffe</td>
<td align="center">B - C</td>
<td align="center">-3.1</td>
<td align="center">NA</td>
<td align="center">NA</td>
<td align="center">NA</td>
<td align="center">0.1779</td>
</tr>
<tr class="odd">
<td align="center">Scheffe</td>
<td align="center">B - D</td>
<td align="center">-0.8</td>
<td align="center">NA</td>
<td align="center">NA</td>
<td align="center">NA</td>
<td align="center">0.9506</td>
</tr>
<tr class="even">
<td align="center">Scheffe</td>
<td align="center">C - D</td>
<td align="center">2.3</td>
<td align="center">NA</td>
<td align="center">NA</td>
<td align="center">NA</td>
<td align="center">0.4253</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="planificacion-del-tamano-muestral" class="section level2">
<h2><span class="header-section-number">5.16</span> Planificación Del Tamaño Muestral</h2>
<p><strong>Diseño De Estudios De ANOVA</strong></p>
<p>La planificación de los tamaños muestrales es una parte integral del diseño en
un estudio de ANOVA. Se asumirá que todos los niveles del factor tienen el mismo
tamaño muestral</p>
<div id="potencia-de-la-prueba-f" class="section level3">
<h3><span class="header-section-number">5.16.1</span> Potencia De La Prueba F</h3>
<p>La potencia de la prueba <span class="math inline">\(F\)</span> es la probabilidad de rechazar <span class="math inline">\(H_{0}\)</span> cuando
<span class="math inline">\(H_{0}\)</span> es falsa, o también se puede pensar como la probabilidad de no
rechazar <span class="math inline">\(H_{a}\)</span> cuando <span class="math inline">\(H_{a}\)</span> es cierta. Específicamente la potencia está
dada por la siguiente expresión:</p>
<p><span class="math display">\[
P = P\left( F^{*} &gt; F_{\left( \alpha;I - 1,N - I \right)}\left| \phi \right.\  \right)
\]</span></p>
<p>donde <span class="math inline">\(\mathbf{\phi}\)</span> es un parámetro de no-centralidad, que es una medida de cuan
distintas son las <span class="math inline">\(\mu_i\)</span>:</p>
<p><span class="math display">\[
\phi = \frac{1}{\sigma}\sqrt{\frac{\sum_{}^{}{n_{i}\left( \mu_{i} - \mu_{\bullet} \right)^{2}}}{I}}
\]</span></p>
<p>y</p>
<p><span class="math display">\[
\mu_{\bullet} = \frac{\sum_{}^{}{n_{i}\mu_{i}}}{N}
\]</span></p>
<p>Cuando todos los tamaños muestrales son iguales, el parámetro ϕ es:</p>
<p><span class="math display">\[
\phi = \frac{1}{\sigma}\sqrt{\frac{n\sum_{}^{}\left( \mu_{i} - \mu_{\bullet} \right)^{2}}{I}}\text{con}\ n = n_{i}
\]</span></p>
<p>donde:</p>
<p><span class="math display">\[
\mu_{} = \frac{\sum_{}^{}\mu_{i}}{I}
\]</span></p>
<p>Para determinar la potencia, se necesita utilizar la distribución F no-centrada,
dado que ésta es la distribución muestral de <span class="math inline">\(F^{*}\)</span> cuando <span class="math inline">\(H_{a}\)</span> es
cierta. Los cálculos son bastantes complejos, pero se han preparado gráficos que
permiten determinar la potencia relativamente fácil. Estos son los gráficos de
Pearson-Hartley de la potencia de la prueba <span class="math inline">\(F\)</span>. La curva a utilizar depende
del número de niveles del factor, del tamaño muestral y del nivel de
significación empleado en la regla de decisión. Estos gráficos se usan de la
siguiente forma:</p>
<p>Cada página se refiere a diferentes <span class="math inline">\(\nu_{1}\)</span>, los grados de libertad del
numerador de <span class="math inline">\(F^{*}\)</span>. Para el modelo de ANOVA <span class="math inline">\(\nu_{1} = I1\)</span>.</p>
<p>Dos niveles de significación, indicados por <span class="math inline">\(\alpha\)</span>, son usados en los
gráficos, <span class="math inline">\(\alpha = 0.05\)</span> y <span class="math inline">\(\alpha = 0.01\)</span>. Hay dos escalas de <span class="math inline">\(X\)</span>,
dependiendo de cual es el nivel de significación empleado. De esta forma, el
grupo de curvas de la izquierda corresponde a <span class="math inline">\(\alpha = 0.05\)</span> y el de la
derecha a <span class="math inline">\(\alpha = 0.01\)</span>.</p>
<p>Hay curvas separadas para diferentes valores de <span class="math inline">\(\nu_{2}\)</span>, los grados de
libertad del denominador de <span class="math inline">\(F^{*}\)</span>. Para el modelo de ANOVA <span class="math inline">\(\nu_{2} = NI\)</span>.
Las curvas son indicadas de acuerdo al valor de <span class="math inline">\(\nu_{2}\)</span>, en la parte
superior del gráfico. Dado que sólo son usados en la tabla valores seleccionados
de <span class="math inline">\(\nu_{2}\)</span>, es necesario interpolar para valores intermedios de <span class="math inline">\(\nu_{2}\)</span></p>
<p>La escala de <span class="math inline">\(X\)</span> representa a <span class="math inline">\(\phi\)</span>, el parámetro no-central.</p>
<p>La escala de <span class="math inline">\(Y\)</span> da la potencia <span class="math inline">\(1 - \beta\)</span>, donde <span class="math inline">\(\beta\)</span> es la
probabilidad de cometer el error de tipo II.</p>
<p><strong>Ejemplo 3</strong>.- Consideremos el caso donde <span class="math inline">\(\nu_{1} = 2\)</span>, <span class="math inline">\(\nu_{2} = 10\)</span>,
<span class="math inline">\(\phi = 10\)</span> y <span class="math inline">\(\alpha = 0.05\)</span>. Si buscamos en la tabla la potencia es <span class="math inline">\(1 - \beta = 0.983\)</span> aproximadamente.</p>
<p>Una forma alternativa para determinar la potencia es especificar la mínima
diferencia que se desea detectar entre las medias de las dos poblaciones más
diferentes. Designaremos a esta diferencia mínima detectable <span class="math inline">\(\delta\)</span>,
calculamos entonces:</p>
<p><span class="math display">\[
\phi = \sqrt{\frac{n\delta^{2}}{2IS^{2}}}
\]</span></p>
<p><strong>Ejemplo 4</strong>.- Supongamos que especificamos que trabajaremos con <span class="math inline">\(n = 10\)</span>, y
que deseamos detectar, entre cuatro tratamientos, diferencias entre las medias
de al menos 4 unidades. De un estudio piloto se sabe que <span class="math inline">\(S^{2} = 7.5888\)</span>.
Trabajamos con <span class="math inline">\(\alpha = 0.05\)</span>.</p>
<p><span class="math inline">\(I\  = \ 4\nu_{1} = 3\)</span> <span class="math inline">\(n = 10\)</span> <span class="math inline">\(\nu_{2} = 36\)</span> <span class="math inline">\(\delta = 4.0\)</span> <span class="math inline">\(S^{2} = 7.5888\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\phi &amp;= \sqrt{\frac{n\delta^{2}}{2IS^{2}}}\\
\phi &amp;= \sqrt{\frac{10\left( 4.0 \right)^{2}}{2\left( 4 \right)\left( 7.5888 \right)}}\\
\phi &amp;= \sqrt{2.6355}\\
\phi &amp;= 1.62
\end{aligned}
\]</span></p>
<p>En la tabla obtenemos una potencia igual a <span class="math inline">\(0.72\)</span>; lo que implica una
probabilidad de cometer el error de tipo II del <span class="math inline">\(28\%\)</span>.</p>
<p>Si bien es deseable estimar la potencia antes de realizar el ANOVA, es útil,
también, preguntarse con que potencia se ha realizado un ANOVA. Esto es
especialmente interesante si la <span class="math inline">\(H_{0}\)</span> no se ha rechazado, pues entonces es
deseable saber cuan bien la prueba detecta las diferencias entre las medias de
la población.</p>
<p>Calculamos <span class="math inline">\(\phi\)</span>, de la siguiente forma:</p>
<p><span class="math display">\[
\phi = \sqrt{\frac{\left( I - 1 \right)\left( CM_E - S^{2} \right)}{IS^{2}}}
\]</span></p>
<p><strong>Ejemplo 5.</strong>- Los datos de la tabla corresponden a una muestra recogida de
tres poblaciones de aves geográficamente aisladas. Se midió la longitud del pico
con una precisión de un décimo de mm; obteniéndose los siguientes datos:</p>
<table>
<thead>
<tr class="header">
<th>Población</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>B</td>
<td>C</td>
</tr>
<tr class="even">
<td>4.2</td>
<td>3.8</td>
<td>3.0</td>
</tr>
<tr class="odd">
<td>3.3</td>
<td>4.1</td>
<td>3.5</td>
</tr>
<tr class="even">
<td>2.8</td>
<td>5.0</td>
<td>4.5</td>
</tr>
<tr class="odd">
<td>4.3</td>
<td>4.6</td>
<td>4.4</td>
</tr>
<tr class="even">
<td>3.7</td>
<td>5.1</td>
<td></td>
</tr>
<tr class="odd">
<td>4.5</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>3.6</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><span class="math display">\[
\begin{aligned}
H_{0}&amp;:\ u_{A} = u_{B} = u_{C}\\
H_{a}&amp;:\ \text{No todas las medias de las poblaciones son iguales.}
\end{aligned}
\]</span></p>
<table>
<thead>
<tr class="header">
<th>Fte. de Variación</th>
<th>SC</th>
<th>GL</th>
<th>CM</th>
<th>F</th>
<th>P</th>
<th>VC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Entre Dentro</td>
<td>1.7977143 5.0322857</td>
<td>2 13</td>
<td>0.8988571 0.3870989</td>
<td>2.322</td>
<td>0.137322</td>
<td>3.806</td>
</tr>
<tr class="even">
<td>Total</td>
<td>6.83</td>
<td>15</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>No rechazamos <span class="math inline">\(H_{0}\)</span> con <span class="math inline">\(p &gt; 0.05\)</span></p>
<p><span class="math display">\[
\phi = \sqrt{\frac{\left( I - 1 \right)\left( CM_E - S^{2} \right)}{IS^{2}}} = \sqrt{\frac{\left( 3 - 1 \right)\left( 0.898871 - 0.387098 \right)}{3\left( 0.3870989 \right)}} = 0.9388053
\]</span></p>
<p>Consultando la tabla la Potencia es 0.25; por lo cual la probabilidad de cometer
error de tipo II es aproximadamente de 0.75.</p>
<ul>
<li><p>Se puede observar que grandes valores de <span class="math inline">\(\phi\)</span> están asociados con
grandes potencias, de las ecuaciones vistas anteriormente se ve que <span class="math inline">\(\phi\)</span>
se incrementa con:</p></li>
<li><p>incremento del tamaño muestral;</p></li>
<li><p>incremento entre las diferencias de las medias de las poblaciones (medida ya
sea por <span class="math inline">\(CM_E\)</span> , o por <span class="math inline">\(\sum_{}^{}\left( \mu_{i} - \mu_{} \right)^{2}\)</span>
o por la mínima diferencia detectable);</p></li>
<li><p>un bajo número de niveles del factor o de tratamientos;</p></li>
<li><p>una disminución de la variabilidad dentro de las poblaciones,
<span class="math inline">\(\sigma^{2}\)</span>, estimada por <span class="math inline">\(S^{2}\)</span> o el <span class="math inline">\(CM_D\)</span>.</p></li>
</ul>
<p><strong>Ejemplo 6.-</strong> Veamos qué pasa con el experimento anterior al aumentar el
tamaño de la muestra.</p>
<table>
<thead>
<tr class="header">
<th>POBLACIÓN</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>B</td>
<td>C</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>3.9</td>
<td>4.6</td>
<td>3.7</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>3.5</td>
<td>4.1</td>
<td>4.2</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>4.1</td>
<td>4.5</td>
<td>3.6</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>4.4</td>
<td>4.4</td>
<td>4.0</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>4.4</td>
<td>3.7</td>
<td>3.3</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>4.6</td>
<td>4.6</td>
<td>3.5</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>3.3</td>
<td>3.9</td>
<td>4.0</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>3.9</td>
<td>4.6</td>
<td>4.4</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>4.4</td>
<td>4.5</td>
<td>3.5</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>3.6</td>
<td>3.7</td>
<td>4.1</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>3.7</td>
<td>4.1</td>
<td>3.9</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>3.4</td>
<td>4.2</td>
<td>4.3</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th>Fte. de Variación</th>
<th>SC</th>
<th>GL</th>
<th>CM</th>
<th>F</th>
<th>p</th>
<th>VC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Entre</td>
<td>0.9433318</td>
<td>2</td>
<td>0.4716659</td>
<td>3.179</td>
<td>0.05458498</td>
<td>3.285</td>
</tr>
<tr class="even">
<td>Dentro</td>
<td>4.89465511</td>
<td>33</td>
<td>0.14832288</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Total</td>
<td>5.8379869</td>
<td>35</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><span class="math display">\[
\mathbf{\phi}\  \approx \ 1.21
\]</span></p>
<p>La potencia es entonces 0.4</p>
<p>Para el uso de las tablas vistas anteriormente se hace necesario la realización
de un experimento. Pero existen tablas que proporcionan los tamaños muestrales
adecuados directamente. Este método es aplicable cuando todos los niveles del
factor tienen el mismo tamaño muestral, esto es <span class="math inline">\(n = n_{i}\)</span>.</p>
<p>La planificación del tamaño de la muestra usando estas tablas se hace en
términos del parámetro de no-centralidad, para tamaños muestrales iguales. Sin
embargo, en lugar de requerir una especificación directa de los niveles de
<span class="math inline">\(u_{i}\)</span> para los cuales es importante controlar la probabilidad de cometer el
error de tipo II; esta tabla sólo requiere una especificación del rango mínimo
de las medias de los niveles del factor para los cuales es importante detectar
diferencias entre los <span class="math inline">\(u_{i}\)</span>, con alta probabilidad. Este rango mínimo se
indica <span class="math inline">\(\Delta\)</span>:</p>
<p><span class="math display">\[
\Delta = max\left( u_{i} \right)min\left( u_{i} \right)
\]</span></p>
<p>Las siguientes especificaciones son necesarias para hacer uso de la tabla:</p>
<ol style="list-style-type: decimal">
<li><p>El nivel de significación <span class="math inline">\(\alpha\)</span></p></li>
<li><p>La magnitud del rango mínimo <span class="math inline">\(\Delta\)</span> de los <span class="math inline">\(u_{i}\)</span>, la cual es
importante detectar con alta probabilidad. La magnitud de <span class="math inline">\(\sigma\)</span>, la
desviación estándar de <span class="math inline">\(Y\)</span>, debe también ser especificada para entrar en
la tabla en términos del cociente: <span class="math inline">\(\frac{\Delta}{\sigma}\)</span></p></li>
<li><p>El nivel de <span class="math inline">\(\beta\)</span>. Entrar en la tabla en términos de <span class="math inline">\(1 - \beta\)</span>.</p></li>
</ol>
<p>Cuando se usa la tabla están disponibles cuatro niveles de <span class="math inline">\(\alpha\
(0.2;0.1;0.05\ y\ 0.01)\)</span>. También hay cuatro niveles de β a través de la
potencia. La tabla provee tamaños muestrales para estudios <span class="math inline">\(\text{de}\ I = 2,\ldots,10\)</span> niveles del factor o tratamientos.</p>
<p><strong>Ejemplo 7.</strong>- 1) Supongamos que se quiere con un rango mínimo <span class="math inline">\(\Delta = 3\)</span>,
para comparar cuatro tratamientos. Se sabe por estudios anteriores que
<span class="math inline">\(\sigma\)</span> es aproximadamente igual a 2. Los niveles para controlar los errores
son:</p>
<p><span class="math display">\[
\alpha = 0.05\ \beta = 0.10\ o\ P = 1 - \beta = 0.90
\]</span></p>
<p>Entramos a la tabla para <span class="math inline">\(\frac{\Delta}{\sigma} = \frac{3}{2} = 1.5\)</span>; <span class="math inline">\(\alpha = 0.05\)</span>; <span class="math inline">\(1 - \beta = 0.9\)</span> e <span class="math inline">\(I = 4\)</span>. Encontramos que <span class="math inline">\(n = 14\)</span>.</p>
<p>Especificación de <span class="math inline">\(\frac{\Delta}{\sigma}\)</span> directa: El rango mínimo también se
puede especificar en términos de unidades de desviación estándar.</p>
<p><span class="math display">\[
\frac{\Delta}{\sigma} = \frac{k\sigma}{\sigma} = k
\]</span></p>
<p>En nuestro ejemplo supongamos que el rango de las medias es k = 2 o más.
Supongamos que las otras especificaciones son:</p>
<p><span class="math display">\[
\alpha = 0.01\ \beta = 0.05\ o\ 1 - \beta = 0.95
\]</span></p>
<p>En la tabla encontramos que <span class="math inline">\(n = 9\)</span>.</p>
<ol start="2" style="list-style-type: decimal">
<li>En el ejemplo se hace necesario incrementar el tamaño de la muestra. Para
ello nos preguntamos cuál es el tamaño de muestra necesario para, trabajando con
<span class="math inline">\(\alpha = 0.05\)</span>, tener una potencia de <span class="math inline">\(0.80\)</span> para detectar diferencias tan
pequeñas como <span class="math inline">\(0.7\)</span>. Suponemos que <span class="math inline">\(S^{2} = 0.3870989\)</span> es una buena
estimación de <span class="math inline">\(\sigma^{2}\)</span>.</li>
</ol>
<p>Entramos a la tabla para <span class="math inline">\(\frac{\Delta}{\sigma} = \frac{0.6}{\sqrt{0.387089}} \approx 1\)</span>; <span class="math inline">\(\alpha = 0.05\)</span>; <span class="math inline">\(1 - \beta = 0.8\)</span> e <span class="math inline">\(I = 3\)</span></p>
<p>Encontramos que <span class="math inline">\(n = 21\)</span>.</p>
</div>
</div>
<div id="modelo-ii-de-anova-niveles-del-factor-aleatorios" class="section level2">
<h2><span class="header-section-number">5.17</span> Modelo II De ANOVA: Niveles Del Factor Aleatorios</h2>
<p>Existen situaciones en las cuales los niveles del factor o los tratamientos
empleados no tienen un interés en sí mismos, pero constituyen una muestra de la
población. El Modelo II de ANOVA está diseñado para este tipo de situaciones.</p>
<div id="modelo-aleatorio-de-medias-de-celdas." class="section level3">
<h3><span class="header-section-number">5.17.1</span> Modelo Aleatorio de Medias de Celdas.</h3>
<p>El modelo II de ANOVA para un factor es:</p>
<p><span class="math display">\[
Y_{ij}\  = \ u_{i}\  + \ \varepsilon_{ij}
\]</span></p>
<p>donde</p>
<p><span class="math inline">\(u_{i}\)</span> son variables independientes <span class="math inline">\(\sim N\left( \mu_{\bullet},\sigma_{\mu}^{2} \right)\)</span></p>
<p><span class="math inline">\(\varepsilon{ij}\)</span> son variables independientes <span class="math inline">\(\sim N\left( 0,\sigma^{2} \right)\)</span></p>
<p><span class="math inline">\(u_{i}\)</span> y <span class="math inline">\(\varepsilon_{ij}\)</span> son variables aleatorias independientes</p>
<p><span class="math display">\[
i = 1,\ 2,\ldots,\ I;\ j = 1,\ 2,\ \ldots,\ n_{i}
\]</span></p>
</div>
<div id="caracteristicas-importantes-del-modelo-1" class="section level3">
<h3><span class="header-section-number">5.17.2</span> Características importantes del Modelo</h3>
<p>El valor esperado de una observación <span class="math inline">\(Y_{ij}\)</span> es:</p>
<p><span class="math display">\[
E(Y_{ij}) = u_{\bullet}
\]</span></p>
<p>esto se debe a que:</p>
<p><span class="math display">\[
\begin{aligned}
E\left( Y_{ij} \right)&amp; = E\left( u_{\bullet}\  \right) + \ E\left( \varepsilon_{ij} \right) \\
&amp; = \ u_{\bullet}\ \  + \ 0 \\
&amp; = \ u_{\bullet} \\
\end{aligned}
\]</span></p>
<p>La varianza de <span class="math inline">\(Y_{ij}\)</span>, que se indica <span class="math inline">\(\sigma_{Y}^{2}\)</span>, es:</p>
<p><span class="math display">\[
\text{Var}\left( Y_{ij} \right) = \sigma_{Y}^{2} = \sigma_{\mu}^{2} + \sigma^{2}
\]</span></p>
<p>A causa de que la varianza de Y en este modelo es la suma de dos componentes,
este modelo se llama, algunas veces, un modelo de componentes de la varianza.</p>
<p>Los <span class="math inline">\(Y_{ij}\)</span> están normalmente distribuidos pues son una combinación
lineal de variables independientes, <span class="math inline">\(u_{i}\)</span> y <span class="math inline">\(\varepsilon_{ij}\)</span>,
distribuidas normalmente</p>
<p>Las <span class="math inline">\(Y_{ij}\)</span> para el modelo aleatorio son sólo independientes si
pertenecen a diferentes tratamientos o niveles del factor. Se puede demostrar
que la covarianza para cualesquiera dos observaciones <span class="math inline">\(Y_{ij}\)</span> e
<span class="math inline">\(Y_{{ij}&#39;}\)</span>, para el mismo nivel i con un modelo II es:</p>
<p><span class="math display">\[
Cov(Y_{ij},\ Y_{ij&#39;}) = \sigma_{Y}^{2}\; \forall\ j \neq  j
\]</span></p>
<p>El modelo II supone que la covarianza entre cualesquiera dos observaciones para
el mismo nivel del factor es constante para todos los niveles del factor.</p>
<p>Una vez que los niveles del factor han sido seleccionados, el modelo II asume
que dos observaciones cualesquiera para el mismo nivel del factor son
independientes pues la media del nivel del factor µi es entonces fijada y las
dos observaciones difieren sólo por los términos del error <span class="math inline">\(\varepsilon_{ij}\)</span>.</p>
</div>
<div id="cuestiones-de-interes" class="section level3">
<h3><span class="header-section-number">5.17.3</span> Cuestiones de Interés</h3>
<p>Cuando el modelo aleatorio es apropiado, uno no está particularmente interesado
en inferencias sobre un <span class="math inline">\(u_{i}\)</span> particular incluido en el estudio, ya sea si
es grande o pequeño, pero sí en inferencias acerca de la población completa de
<span class="math inline">\(mu_{i}\)</span>. Específicamente, el interés a menudo se centra sobre la media de los
<span class="math inline">\(mu_{i}\)</span>, <span class="math inline">\(u_{}\)</span>, y en la variabilidad de los <span class="math inline">\(mu_{i}\)</span> medida por
<span class="math inline">\(\sigma_{\mu}^{2}\)</span>.</p>
<p>Dado que <span class="math inline">\(\sigma_{\mu}^{2}\)</span> es una medida directa de la variabilidad de los
<span class="math inline">\(mu_{i}\)</span>, el efecto de esa variabilidad, a menudo, es medido por el cociente:</p>
<p><span class="math display">\[
\frac{\sigma_{\mu}^{2}}{\sigma_{\mu}^{2} + \sigma^{2}}
\]</span></p>
<ol style="list-style-type: decimal">
<li><p>El cociente toma valores entre <span class="math inline">\(0\ (\sigma^{2} = \infty)\)</span> y <span class="math inline">\(1\
(\sigma^{2} = 0)\)</span>.</p></li>
<li><p>El denominador es <span class="math inline">\(\sigma_{Y}^{2}\)</span>.</p></li>
</ol>
<p>En vista de las propiedades 1 y 2, el cociente mide la proporción de la
variabilidad total de los <span class="math inline">\(Y_{ij}\)</span> que se debe a la variabilidad en los
<span class="math inline">\(\mu_{i\bullet}\)</span>.</p>
</div>
<div id="prueba-para-mathbfsigma_mathbfmumathbf2-0" class="section level3">
<h3><span class="header-section-number">5.17.4</span> Prueba para <span class="math inline">\(\mathbf{\sigma}_{\mathbf{\mu}}^{\mathbf{2}}\)</span> = 0</h3>
<p>Consideremos como decidir entre</p>
<p><span class="math display">\[
H_{0}:\ \sigma_{\mu}^{2} = 0
\]</span></p>
<p><span class="math display">\[
H_{a}:\ \sigma_{\mu}^{2} &gt; 0
\]</span></p>
<p><span class="math inline">\(H_{0}\)</span> implica que todos los <span class="math inline">\(mu_{i}\)</span> son iguales, esto es, <span class="math inline">\(mu_{i} = u_{\bullet}\)</span>. <span class="math inline">\(H_{a}\)</span> implica que los <span class="math inline">\(mu_{i}\)</span> difieren.</p>
<p>La diferencia entre los dos modelos aparece en los valores esperados de los
cuadrados medios. Se puede demostrar de misma forma que lo hemos hecho para el
modelo I, que:</p>
<p><span class="math display">\[
E(CM_D) = \sigma^{2}
\]</span></p>
<p><span class="math display">\[
E\left( CM_E \right) = \sigma^{2} + \ n\sigma_{\mu}^{2}
\]</span></p>
<p>donde</p>
<p><span class="math display">\[
n = \frac{1}{I - 1}\left\lbrack \left( \sum_{}^{}n_{i} \right) - \frac{\sum_{}^{}n_{i}^{2}}{\sum_{}^{}n_{i}} \right\rbrack
\]</span></p>
<p>Sí todos los <span class="math inline">\(n_{i} = n\)</span>, entonces <span class="math inline">\(n = n\)</span></p>
<p>Es claro que si <span class="math inline">\(\sigma_{\mu}^{2} = 0\)</span>, el <span class="math inline">\(CM_D\)</span> y el <span class="math inline">\(CM_E\)</span> tienen
el mismo valor esperado <span class="math inline">\(\sigma^{2}\)</span>. Por otro lado <span class="math inline">\(E\left( CM_E \right) &gt; \ E(CM_D)\)</span> dado que <span class="math inline">\(n &gt; 0\)</span> siempre. En consecuencia, grandes valores de la
prueba estadística:</p>
<p><span class="math display">\[
F^{*} = \frac{CM_E}{CM_D}
\]</span></p>
<p>nos llevará a rechazar <span class="math inline">\(H_{0}\)</span>. Dado que <span class="math inline">\(F^{*}\)</span> sigue la distribución <span class="math inline">\(F\)</span>
cuando <span class="math inline">\(H_{0}\)</span> es verdadera, la regla de decisión es la misma que para el
modelo I:</p>
<p>Si <span class="math inline">\(F^{*} \leq F_{(1 - \alpha;I - 1;\ N - I)}\)</span> no se rechaza <span class="math inline">\(H_{0}\)</span>.</p>
<p>Si <span class="math inline">\(F^{*} &gt; F^{*} \leq F_{(1 - \alpha;I - 1;\ N - I)}\)</span> se rechaza <span class="math inline">\(H_{0}\)</span>.</p>
<p><strong>Ejemplo 8.-</strong> Un laboratorio emplea una cierta técnica para determinar el
contenido de fósforo en el forraje del ganado bovino. La cuestión planteada es
“<em>si las determinaciones de fósforo dependen de las técnicas empleadas para el
análisis</em>”. Para contestar esta pregunta se seleccionaron al azar cuatro
técnicas con cinco observaciones para la misma tanda de forraje, obteniéndose
los siguientes resultados:</p>
<table>
<thead>
<tr class="header">
<th>Técnica 1</th>
<th>Técnica 2</th>
<th>Técnica 3</th>
<th>Técnicas 4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>34</td>
<td>37</td>
<td>34</td>
<td>36</td>
</tr>
<tr class="even">
<td>36</td>
<td>36</td>
<td>37</td>
<td>34</td>
</tr>
<tr class="odd">
<td>34</td>
<td>35</td>
<td>35</td>
<td>37</td>
</tr>
<tr class="even">
<td>35</td>
<td>37</td>
<td>37</td>
<td>34</td>
</tr>
<tr class="odd">
<td>34</td>
<td>37</td>
<td>36</td>
<td>35</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(H_{0}\)</span>: La determinación del contenido de fósforo no difiere entre las
técnicas.</p>
<p><span class="math inline">\(H_{a}:\)</span> La determinación del contenido de fósforo difiere entre técnicas.</p>
<table style="width:100%;">
<colgroup>
<col width="16%" />
<col width="3%" />
<col width="3%" />
<col width="5%" />
<col width="4%" />
<col width="7%" />
<col width="7%" />
<col width="26%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th>Fte. de Variación</th>
<th>SC</th>
<th>GL</th>
<th>CM</th>
<th>F</th>
<th>p</th>
<th>VC</th>
<th>General</th>
<th>Ejemplo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Entre</td>
<td>9</td>
<td>3</td>
<td>3</td>
<td>2.4</td>
<td>0.10589</td>
<td>3.23886</td>
<td><span class="math inline">\(\sigma^2 + n´ \sigma_{\mu}^{2}\)</span></td>
<td><span class="math inline">\(\sigma^2 + 5 \sigma_{\mu}^{2}\)</span></td>
</tr>
<tr class="even">
<td>Dentro</td>
<td>20</td>
<td>16</td>
<td>1.25</td>
<td></td>
<td></td>
<td></td>
<td><span class="math inline">\(\sigma^2\)</span></td>
<td><span class="math inline">\(\sigma^2\)</span></td>
</tr>
<tr class="odd">
<td>Total</td>
<td>29</td>
<td>19</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>No se rechaza <span class="math inline">\(H_0\)</span></p>
<table>
<thead>
<tr class="header">
<th>Niveles del Factor</th>
<th><span class="math inline">\(n_{i}\)</span></th>
<th>Media muestral</th>
<th>Varianza muestral</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>5</td>
<td>34.6</td>
<td>0.8</td>
</tr>
<tr class="even">
<td>2</td>
<td>5</td>
<td>36.4</td>
<td>0.8</td>
</tr>
<tr class="odd">
<td>3</td>
<td>5</td>
<td>35.8</td>
<td>1.7</td>
</tr>
<tr class="even">
<td>4</td>
<td>5</td>
<td>35.2</td>
<td>1.7</td>
</tr>
</tbody>
</table>
</div>
<div id="estimacion-de-mathbfmu_mathbfbullet" class="section level3">
<h3><span class="header-section-number">5.17.5</span> Estimación De <span class="math inline">\(\mathbf{\mu}_{\mathbf{\bullet}}\)</span></h3>
<p>Se sabe que:</p>
<p><span class="math display">\[
E(Y_{ij}) = u_{\bullet}
\]</span></p>
<p>Así, un estimador insesgado de <span class="math inline">\(\mu_{\bullet}\)</span> es:</p>
<p><span class="math display">\[
{\hat{\mu}}_{i} = {\overline{Y}}_{\bullet\bullet}
\]</span></p>
<p>Se puede demostrar que la varianza de este estimador es:</p>
<p><span class="math display">\[
S^{2}\left( {\overline{Y}}_{\bullet\bullet} \right) = \frac{\sigma_{\mu}^{2}}{I} + \frac{\sigma^{2}}{N} = \frac{n\sigma_{\mu}^{2} + \sigma^{2}}{N}
\]</span></p>
<p>Recordar que <span class="math inline">\(N = I\ n.\)</span></p>
<p>Se ve que la varianza está formada por dos componentes.</p>
<p>Un estimador insesgado de esta varianza es:</p>
<p><span class="math display">\[
S^{2}\left( {\overline{Y}}_{\bullet\bullet} \right) = \frac{CM_E}{N}
\]</span></p>
<p>es un estimador insesgado pues, cuando ni = n:</p>
<p><span class="math display">\[
E\left( CM_E \right) = n\sigma_{\mu}^{2} + \sigma^{2}
\]</span></p>
<p>Se puede demostrar que:</p>
<p><span class="math inline">\(\frac{{\overline{Y}}_{\bullet\bullet} - \mu_{\bullet}}{S\left( {\overline{Y}}_{\bullet\bullet} \right)}\sim t_{\left( I - 1 \right)}\)</span>, cuando
<span class="math inline">\(n_{i} = n.\)</span></p>
<p>Así, de la forma usual se obtienen los límites del intervalo de confianza para
µ•:</p>
<p><span class="math display">\[
{\overline{Y}}_{\bullet\bullet} \pm t_{I - 1;\alpha\left( 2 \right)}S\left( {\overline{Y}}_{\bullet\bullet} \right)
\]</span></p>
<p><strong>Ejemplo</strong> 9.- En el estudio de contenido de fósforo del forraje del ganado
bovino. Se tiene:</p>
<p><span class="math display">\[
{\overline{Y}}_{\bullet\bullet} = 35.5\ CM_E = 3\ N = 20
\]</span></p>
<p>Necesitamos <span class="math inline">\(t_{3;\ 0.05\left( 2 \right)} = 3.182\)</span> y <span class="math inline">\(S^{2}\left( {\overline{Y}}_{\bullet \bullet} \right) = \frac{3}{20} = 0.15\)</span>, entonces
<span class="math inline">\(S\left( {\overline{Y}}_{\bullet \bullet} \right) = 0.38729833\)</span>; el intervalo
de confianza del 95% es:</p>
<p><span class="math display">\[
34.27 \leq \ u_{\bullet} \leq 36.73
\]</span></p>
</div>
<div id="estimacion-de-sigma_mu2left-sigma_mu2sigma2-right" class="section level3">
<h3><span class="header-section-number">5.17.6</span> Estimación De <span class="math inline">\(\sigma_{\mu}^2/\left ( \sigma_{\mu}^2+\sigma^2 \right )\)</span></h3>
<p>El cociente <span class="math inline">\(\sigma_{\mu}^2/\left (\sigma_{\mu}^2+\sigma^2 \right )\)</span>
revela el alcance del efecto de la varianza entre los <span class="math inline">\(mu_{i}\)</span>. Para
desarrollar un intervalo de confianza para este cociente, se supone que todos
los tamaños muestrales de los niveles del factor son iguales.</p>
<p>Comenzaremos obteniendo un intervalo de confianza para el cociente
<span class="math inline">\(\frac{\sigma_{\mu}^{2}}{\sigma^{2}}\)</span>. El <span class="math inline">\(CM_E\)</span> y el <span class="math inline">\(CM_D\)</span> son
variables aleatorias independientes para el modelo II de ANOVA, lo mismo que
para el modelo I. Cuando <span class="math inline">\(n_{i} = n\)</span>, se puede demostrar que:</p>
<p><span class="math display">\[
\frac{CM_E}{n\sigma_{\mu}^{2} + \sigma^{2}} + \frac{CM_D}{\sigma^{2}}\sim F_{I - 1,N - I}
\]</span></p>
<p>Así, se puede escribir la probabilidad:</p>
<p><span class="math display">\[
P\left( F_{\left( 1 - \frac{\alpha}{2} \right);I - 1,N - I} \leq \frac{CM_E}{n\sigma_{\mu}^{2} + \sigma^{2}} + \frac{CM_D}{\sigma^{2}} \leq F_{\left( \frac{\alpha}{2} \right);I - 1,N - I} \right) = 1 - \alpha
\]</span></p>
<p>Reordenando las desigualdades, se obtienen los siguientes límites <span class="math inline">\(S\)</span> e <span class="math inline">\(I\)</span>
para <span class="math inline">\(\frac{\sigma_{\mu}^{2}}{\sigma^{2}}\)</span></p>
<p><span class="math display">\[
\begin{matrix}
I = \frac{1}{n}\left\lbrack \frac{CM_E}{CM_D}\left( \frac{1}{F_{\frac{\alpha}{2};I - 1,N - I}} \right) - 1 \right\rbrack \\
S = \frac{1}{n}\left\lbrack \frac{CM_E}{CM_D}\left( \frac{1}{F_{1 - \frac{\alpha}{2};I - 1,N - I}} \right) - 1 \right\rbrack \\
\end{matrix}
\]</span></p>
<p>donde <span class="math inline">\(I\)</span> es el límite inferior y <span class="math inline">\(S\)</span> el superior.</p>
<p>Los límites <span class="math inline">\(I^{*}\)</span> y <span class="math inline">\(S^{*}\)</span> para
<span class="math inline">\(\frac{\mathbf{\sigma}_{\mathbf{\mu}}^{\mathbf{2}}}{\mathbf{\sigma}_{\mathbf{\mu}}^{\mathbf{2}}\mathbf{+}\mathbf{\sigma}^{\mathbf{2}}}\)</span>
pueden ser obtenidos como sigue:</p>
<p><span class="math display">\[
I^{*} = \frac{I}{1 + I}S^{*} = \frac{S}{1 + S}
\]</span></p>
<p><strong>Ejemplo 9 cont</strong>.- En nuestro ejemplo</p>
<p><span class="math display">\[
CM_E = 3\ CM_D = 1.25\ n = 5\ I = 4\ N = 20
\]</span></p>
<p>Para construir el intervalo de confianza del 95% se necesita:</p>
<p><span class="math display">\[
F_{0.975;\ 3,\ 19} = 0.071\ F_{0.025;\ 3,\ 19} = 3.093
\]</span></p>
<p>De esta manera los límites del 95% para <span class="math inline">\(\frac{\sigma_{\mu}^{2}}{\sigma^{2}}\)</span>
son:</p>
<p><span class="math display">\[
I = \frac{1}{5}\left\lbrack \frac{3}{1.25}\left( \frac{1}{3.093} \right) - 1 \right\rbrack = - 0.077S = \frac{1}{5}\left\lbrack \frac{3}{1.25}\left( \frac{1}{0.071} \right) - 1 \right\rbrack = 6.561
\]</span></p>
<p>Cuando el límite inferior del intervalo de confianza para
<span class="math inline">\(\frac{\sigma_{\mu}^{2}}{\sigma^{2}}\)</span> es negativo, la práctica usual es
considerarlo como 0. Entonces el intervalo de confianza es:</p>
<p><span class="math display">\[
0 \leq \frac{\sigma_{\mu}^{2}}{\sigma^{2}} \leq 6.561
\]</span></p>
<p>Finalmente, los límites de confianza para
<span class="math inline">\(\frac{\mathbf{\sigma}_{\mathbf{\mu}}^{\mathbf{2}}}{\mathbf{\sigma}_{\mathbf{\mu}}^{\mathbf{2}}\mathbf{+}\mathbf{\sigma}^{\mathbf{2}}}\)</span>
son:</p>
<p><span class="math display">\[
0\  \leq \text{  }\frac{\mathbf{\sigma}_{\mathbf{\mu}}^{\mathbf{2}}}{\mathbf{\sigma}_{\mathbf{\mu}}^{\mathbf{2}}\mathbf{+}\mathbf{\sigma}^{\mathbf{2}}} \leq \ 0.87
\]</span></p>
<p>Concluimos que la variabilidad de la media de las determinaciones de fósforo se
encuentra entre 0 y 87% de la varianza total.</p>
<p><strong>Estimación de σ2 y</strong> <span class="math inline">\(\mathbf{\sigma}_{\mathbf{\mu}}^{\mathbf{2}}\)</span></p>
<p>Un estimador insesgado para <span class="math inline">\(\sigma^{2}\)</span> es:</p>
<p><span class="math display">\[
{\overset{\land}{\sigma}}^{2} = CM_D
\]</span></p>
<p>Y el intervalo de confianza se obtiene como:</p>
<p><span class="math display">\[
\frac{\left( N - I \right)S^{2}}{\chi_{0.025;N - I}^{2}} \leq \sigma^{2} \leq \frac{\left( N - I \right)S^{2}}{\chi_{0.975,N - I}^{2}}
\]</span></p>
<p>También se puede obtener un estimador insesgado de <span class="math inline">\(\sigma_{\mu}^{2}\)</span>:</p>
<p><span class="math display">\[
E(CM_D) = \sigma^{2}
\]</span></p>
<p><span class="math display">\[
E(CM_E) = \sigma^{2} + n\sigma_{\mu}^{2}
\]</span></p>
<p>Se sigue que:</p>
<p><span class="math display">\[
{\overset{\land}{\sigma}}_{\mu}^{2} = \frac{CM_E - CM_D}{n}
\]</span></p>
<p><strong>Ejemplo 9 cont.</strong>-</p>
<p><span class="math display">\[
CM_D = 1.25\; \chi_{0.975,16}^{2} = 6.908\; \chi_{0.025;16}^{2} = 28.845
\]</span></p>
<p>El intervalo de confianza es:</p>
<p><span class="math display">\[
0.693 = \frac{16\left( 1.25 \right)}{28.845} \leq \sigma^{2} \leq \frac{16\left( 1.25 \right)}{6.908} = 2.895
\]</span></p>
<p>Una estimación insesgada de <span class="math inline">\(\sigma_{\mu}^{2}\)</span> es:</p>
<p><span class="math display">\[
{\overset{\land}{\sigma}}_{\mu}^{2} = \frac{3 - 1.25}{5} = 0.35
\]</span></p>
</div>
<div id="modelo-de-efectos-aleatorios" class="section level3">
<h3><span class="header-section-number">5.17.7</span> Modelo De Efectos Aleatorios</h3>
<p>El modelo se puede expresar como:</p>
<p><span class="math display">\[
Y_{ij} = u_{\bullet} + \alpha_{i} + \varepsilon_{ij}
\]</span></p>
<p>donde</p>
<p><span class="math inline">\(\mu_{\bullet}\)</span> es una componente constante común a todas las observaciones</p>
<p><span class="math inline">\(\alpha_{i}\)</span> son variables aleatorias independientes <span class="math inline">\(\sim N(0,\sigma_{\mu}^{2})\)</span></p>
<p><span class="math inline">\(\varepsilon_{ij}\)</span> son variables aleatorias independientes <span class="math inline">\(\sim N(0,\sigma^{2})\)</span></p>
<p><span class="math inline">\(\alpha_{i}\)</span> y <span class="math inline">\(\varepsilon_{ij}\)</span> son independientes</p>
<p><span class="math display">\[
i = 1,2,\ldots,I;j = 1,2,\ldots,n_{i}
\]</span></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="manejo-de-datos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="problemas-anova-simple.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/anova.Rmd",
"text": "Edit"
},
"download": ["EACN.pdf", "EACN.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
